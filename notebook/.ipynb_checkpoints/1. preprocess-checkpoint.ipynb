{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_strip(_str):\n",
    "    pattern_strip = re.compile('[\\t|\\n|\\s]*')\n",
    "    return re.sub(pattern_strip,'',_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取权利要求 总结数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_df_filename = '../data/processed/claim_df_0619.pkl'\n",
    "claim_dir = '../data/raw_data/claim_info/'\n",
    "if not os.path.isfile(claim_df_filename):\n",
    "    claim_files = []\n",
    "    for _dir,_,file in os.walk(claim_dir):\n",
    "        claim_files+= [os.path.join(_dir,i) for i in file]\n",
    "    claim_df = pd.DataFrame()\n",
    "    claim_df['id'] = [i for i in range(len(claim_files))]\n",
    "    claim_df['pub_id'] = [i.split('/')[-1].split('.')[0] for i in claim_files]\n",
    "    claim_df['info_id'] = [i.split('/')[-2] for i in claim_files]\n",
    "    # claim_df['text'] = [text_strip(BeautifulSoup(open(i).read(),'lxml').text) for i in claim_files]\n",
    "    claim_text = []\n",
    "    for num,i in enumerate(claim_files):\n",
    "        if num%10000==0:\n",
    "            print('[{0}] Num:{1}'.format(time.ctime(),num))\n",
    "        claim_text.append(text_strip(BeautifulSoup(open(i).read(),'lxml').text))\n",
    "    claim_df['text'] = claim_text\n",
    "    claim_df.to_pickle(claim_df_filename)\n",
    "else:\n",
    "    claim_df = pd.read_pickle(claim_df_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取专利详情 总结数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_df_filename = '../data/processed/detail_df_0619.pkl'\n",
    "detail_dir = '../data/raw_data/detail_info/'\n",
    "if not os.path.isfile(detail_df_filename):\n",
    "    detail_files = []\n",
    "    for _dir,_,file in os.walk(detail_dir):\n",
    "        detail_files += [os.path.join(_dir,i) for i in file]\n",
    "    detail_df = pd.DataFrame()\n",
    "    detail_df['id'] = [i for i in range(len(detail_files))]\n",
    "    detail_df['pub_id'] = [i.split('/')[-1].split('.')[0] for i in detail_files]\n",
    "    detail_df['info_id'] = [i.split('/')[-2] for i in detail_files]\n",
    "    detail_data = []\n",
    "    for num,fname in enumerate(detail_files):\n",
    "        if num%10000==0:\n",
    "            print('[{0}] Num:{1}'.format(time.ctime(),num))\n",
    "        temp_json = json.loads(open(fname).read())\n",
    "        detail_data.append(temp_json['data'])\n",
    "    detail_df['data'] = detail_data\n",
    "    detail_df.to_pickle(detail_df_filename)\n",
    "else:\n",
    "    detail_df = pd.read_pickle(detail_df_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取法律信息 总结数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_df_filename = '../data/processed/legal_df_0619.pkl'\n",
    "legal_dir = '../data/raw_data/legal_info/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(legal_df_filename):\n",
    "    legal_files = []\n",
    "    for _dir,_,file in os.walk(legal_dir):\n",
    "        legal_files+=[os.path.join(_dir,i) for i in file]\n",
    "    legal_df = pd.DataFrame()\n",
    "    legal_df['id'] = [i.split('/')[-1].split('.')[0] for i in legal_files]\n",
    "    legal_df['info_id'] = [i.split('/')[-2] for i in legal_files]\n",
    "    legal_df['data'] = [json.loads(open(i).read()) for i in legal_files]\n",
    "    legal_df.to_pickle(legal_df_filename)\n",
    "else:\n",
    "    legal_df = pd.read_pickle(legal_df_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
