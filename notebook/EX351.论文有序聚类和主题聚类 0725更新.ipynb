{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T06:47:12.799274Z",
     "start_time": "2019-07-25T06:47:11.892053Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from datetime import datetime\n",
    "from elasticsearch import Elasticsearch\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T06:47:12.807543Z",
     "start_time": "2019-07-25T06:47:12.803131Z"
    }
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T06:47:13.909461Z",
     "start_time": "2019-07-25T06:47:12.810524Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba.posseg as psg\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T07:02:24.774978Z",
     "start_time": "2019-07-25T07:02:24.698705Z"
    }
   },
   "outputs": [],
   "source": [
    "def tongjiau(li):\n",
    "    authors = []\n",
    "    for i in li:\n",
    "        try:\n",
    "            authors += i\n",
    "        except:\n",
    "            continue\n",
    "    return list(set(authors))\n",
    "\n",
    "def savepickle(name, data):\n",
    "    output = open('%s.pkl' % (name), 'wb')\n",
    "    pkl.dump(data, output)\n",
    "    output.close()\n",
    "\n",
    "def loadpickle(name):\n",
    "    pkl_file = open('%s.pkl' % (name), 'rb')\n",
    "    data1 = pkl.load(pkl_file)\n",
    "    return data1\n",
    "\n",
    "def get_data(key, from_date, to_date, volume):\n",
    "    es4Paper = esPaperRetrieval(host='10.8.128.205',port=49200)\n",
    "    data= es4Paper.Retrieval(titleQuery=key,kwordQuery=key,summaryQuery=key,pubQuery='',\n",
    "              fromDate=from_date,toDate=to_date,volume=volume)\n",
    "    data = pd.DataFrame(data)[[\"P_Author\", \"P_Publication\", \"P_Summary_seg\", \"P_Keyword\", \"P_year\"]]\n",
    "    data.columns = [\"authors\", \"Jounal\", \"seg_abstract\", \"keywords\", \"year\"]\n",
    "    data.year = [i[0:4] for i in data.year]\n",
    "\n",
    "    group_df = data.groupby(by=['year'])\n",
    "    # 统计每年的论文数量\n",
    "    years = list(set(data['year']))\n",
    "    # years.remove(None)\n",
    "    years = sorted([int(i) for i in years])\n",
    "    year_num = []\n",
    "    for y in years:\n",
    "        try:\n",
    "            year_num.append(len(group_df.get_group(str(y))))\n",
    "        except:\n",
    "            year_num.append(0)\n",
    "\n",
    "    # 根据年份将文献信息整合并保存\n",
    "\n",
    "    years_df = pd.DataFrame()\n",
    "    years_df['year'] = years\n",
    "    seg = []\n",
    "    key = []\n",
    "    jou = []\n",
    "    authors = []\n",
    "    for i in years:\n",
    "        seg.append(' '.join(list(group_df.get_group(str(i))['seg_abstract'])))\n",
    "        k = list(group_df.get_group(str(i))['keywords'])\n",
    "        if None in k:\n",
    "            while None in k:\n",
    "                k.remove(None)\n",
    "            key.append(' '.join(k))\n",
    "        else:\n",
    "            key.append(' '.join(k))\n",
    "        jou.append(' '.join(list(group_df.get_group(str(i))['Jounal'])))\n",
    "        authors.append(' '.join(tongjiau(list(group_df.get_group(str(i))['authors']))).split())\n",
    "    years_df['seg_abstract'] = seg\n",
    "    years_df['keywords'] = key\n",
    "    years_df['authors'] = authors\n",
    "    years_df['Jounal'] = jou\n",
    "    years_df['paper_num'] = year_num\n",
    "    savepickle('year_df', years_df)\n",
    "    return years_df\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    top_n = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "#         print(\"Topic #%d:\" % topic_idx)\n",
    "#         print(\" \".join([feature_names[i]\n",
    "#                         for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        top_n.append([feature_names[i]\n",
    "                      for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def build_tfidf(max_feature, data):\n",
    "    #     vectorizer=CountVectorizer()\n",
    "    tfidf = TfidfVectorizer(max_features=max_feature)\n",
    "    f_tfidf = tfidf.fit_transform(data)\n",
    "    word = tfidf.get_feature_names()\n",
    "    f_tfidf = f_tfidf.toarray()\n",
    "    return f_tfidf, word\n",
    "\n",
    "import re\n",
    "def read_s_words(stop_file):\n",
    "    with open(stop_file, 'r', encoding='utf8') as f:\n",
    "        stop_words = set()\n",
    "        for line in f:\n",
    "            stop_words.add(line.strip())\n",
    "    return stop_words\n",
    "def clean_words(strs):\n",
    "    stop_words = read_s_words('../data/paper_data/stopwordPaper.txt')\n",
    "    words = strs.split(' ')\n",
    "    return ' '.join([word for word in words if word not in stop_words and not bool(re.match('.*?\\d.*?', word))])\n",
    "\n",
    "\n",
    "# 用tfidf计算每年的主题\n",
    "# 用tfidf计算每年的主题\n",
    "def tfidf_lda(n_topic, n_top_words, max_feature, data):\n",
    "    tfidf = TfidfVectorizer(max_features=max_feature)\n",
    "    f_tfidf = tfidf.fit_transform(data)\n",
    "    f_tfidf = f_tfidf.toarray()\n",
    "    # print(f_tfidf)\n",
    "    # 主题的个数\n",
    "    n_topics = n_topic\n",
    "    # 主题词个数\n",
    "    n_top_words = n_top_words\n",
    "    n_samples = f_tfidf.shape[0]\n",
    "\n",
    "    n_features = f_tfidf.shape[1]\n",
    "    lda = LatentDirichletAllocation(n_components=n_topics, max_iter=5,\n",
    "                                    learning_method='online',\n",
    "                                    learning_offset=50.,\n",
    "                                    random_state=0)\n",
    "\n",
    "    lda.fit(f_tfidf)\n",
    "    tf_feature_names = tfidf.get_feature_names()\n",
    "\n",
    "    top_30 = print_top_words(lda, tf_feature_names, n_top_words)\n",
    "\n",
    "    top_30_all = print_top_words(lda, tf_feature_names, n_top_words)\n",
    "    top_30_find_weight=[]\n",
    "    for h in range(n_topics):\n",
    "        top_30 = top_30_all[h]\n",
    "        top_30_weight = []\n",
    "        for i in range(len(f_tfidf)):\n",
    "            for j in range(len(tf_feature_names)):\n",
    "                if tf_feature_names[j] in top_30:\n",
    "                    top_30_weight.append(f_tfidf[i][j]+0.1)\n",
    "        top_30_find_weight.append(top_30_weight)\n",
    "    return top_30_all, top_30_find_weight\n",
    "\n",
    "def zhutifenxi( key, n_topic=3, n_top_words=30, year_from=2010, year_to=2018, volume=500):\n",
    "    years_df = get_data(key, str(year_from-1)+\"-12-31\", str(year_to)+\"-12-31\", volume)\n",
    "    years_df['seg_abstract'] = years_df['seg_abstract'].map(clean_words)\n",
    "    max_feature = 2000\n",
    "    result = []\n",
    "    value=[]\n",
    "    result += tfidf_lda(n_topic, n_top_words, max_feature,years_df.loc[years_df.year.isin(range(year_from, year_to + 1))]['seg_abstract'])[0]\n",
    "    value += tfidf_lda(n_topic, n_top_words, max_feature,years_df.loc[years_df.year.isin(range(year_from, year_to + 1))]['seg_abstract'])[1]\n",
    "    key = [[(\"name\", \"value\")] * n_top_words for i in range(n_topic)]\n",
    "    return [[dict(zip(t[0],t[1])) for t in k]  for k in [list(zip(j[0], j[1])) for j in list(zip(key, [list(zip(i[0], i[1])) for i in list(zip(result, value))]))]]\n",
    "def merge_list(x):\n",
    "    y = []\n",
    "    for line in x:\n",
    "        line = line.split(' ')\n",
    "        y = y +  line\n",
    "    return y\n",
    "\n",
    "def newtfidf_lda(n_topic, n_top_words, max_feature, data):\n",
    "    tfidf = TfidfVectorizer(max_features=max_feature)\n",
    "    f_tfidf = tfidf.fit_transform(data)\n",
    "    f_tfidf = f_tfidf.toarray()\n",
    "    # print(f_tfidf)\n",
    "    # 主题的个数\n",
    "    n_topics = n_topic\n",
    "    # 主题词个数\n",
    "    n_top_words = n_top_words\n",
    "    n_samples = f_tfidf.shape[0]\n",
    "\n",
    "    n_features = f_tfidf.shape[1]\n",
    "    lda = LatentDirichletAllocation(n_components=n_topics, max_iter=5,\n",
    "                                    learning_method='online',\n",
    "                                    learning_offset=50.,\n",
    "                                    random_state=0)\n",
    "\n",
    "    lda.fit(f_tfidf)\n",
    "    tf_feature_names = tfidf.get_feature_names()\n",
    "    top_30 = print_top_words(lda, tf_feature_names, n_top_words)\n",
    "    top_30 = top_30[0]\n",
    "    top_30_weight = []\n",
    "    print(top_30)\n",
    "    word_valus = dict(zip(tf_feature_names, f_tfidf[0]))\n",
    "    for word in top_30:\n",
    "        top_30_weight.append(word_valus[word]+0.01)\n",
    "    print(top_30_weight)\n",
    "    return top_30, top_30_weight\n",
    "def youxujulei(key, n_class=4, n_top_topic=30):\n",
    "    years_df = get_data(key, \"2010-12-31\", \"2019-12-31\", 1000)\n",
    "    # 设置特征维度\n",
    "    years_df['seg_abstract'] = years_df['seg_abstract'].map(clean_words)\n",
    "    max_feature = 2000\n",
    "    # 根据年份建立tfidf表\n",
    "    year_tfidf,tf_feature_names  = build_tfidf(max_feature, years_df['seg_abstract'])\n",
    "\n",
    "\n",
    "    # 有序聚类\n",
    "\n",
    "    # 聚类数量\n",
    "    lst = get_one_essay_trace(year_tfidf[0], n_class)\n",
    "    split_result = observe_divided(lst[0], years_df['year'])\n",
    "\n",
    "    split_df = pd.DataFrame()\n",
    "    abstract_agg = []\n",
    "    abstracts = []\n",
    "    for i in split_result:\n",
    "        tmp = []\n",
    "        for y in i:\n",
    "            tmp.append(list(years_df.loc[years_df.year == y]['seg_abstract'])[0])\n",
    "        abstract_agg.append(' '.join(tmp))\n",
    "        abstracts.append(tmp)\n",
    "    split_df['class'] = split_result\n",
    "    split_df['merge_abstract'] = abstract_agg\n",
    "    split_df['abstracts'] = abstracts\n",
    "\n",
    "    # 根据tf计算LDA主题词\n",
    "    # 算法 类名/第i类\n",
    "    result_str = []\n",
    "    keys = [\"pub_id\", \"title\", \"publicationDate\", \"firstApplicant\"]\n",
    "\n",
    "    result1 = []\n",
    "    value1 = []\n",
    "    year = []\n",
    "    for i in range(n_class):\n",
    "        t = 1\n",
    "        n_topic=1\n",
    "        result, value = newtfidf_lda(n_topic, n_top_topic, max_feature, split_df.loc[i, 'seg_abstract'])\n",
    "        result1.append(result)\n",
    "        value1.append(value)\n",
    "        year.append(str(split_df['class'][i]))\n",
    "    key = [[(\"name\", \"value\")] * n_top_topic for i in range(n_class)]\n",
    "    # return result_str\n",
    "    return [[dict(zip(t[0], t[1])) for t in k] for k in [list(zip(j[0], j[1])) for j in list(zip(key, [list(zip(i[0], i[1])) for i in list(zip(result1, value1))]))]],year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T06:48:37.024858Z",
     "start_time": "2019-07-25T06:48:36.989372Z"
    }
   },
   "outputs": [],
   "source": [
    "def distance(a, b):\n",
    "    #  计算两个vector的距离，逐项差的平方和，不开根号\n",
    "    if len(a) != len(b):\n",
    "        print('wrong')\n",
    "        return 0\n",
    "    else:\n",
    "        temp = a - b\n",
    "        temp = temp ** 2\n",
    "        res = sum(temp)\n",
    "        return res\n",
    "def get_dist_mat(feat):\n",
    "    #  输入为特征矩阵，返回一个相似度矩阵（行数乘行数）\n",
    "    print(type(feat))\n",
    "    length=feat.shape[0]#样本数量\n",
    "    wide = feat.shape[1]#特征向量长度\n",
    "    res = np.zeros(shape=(length, length))\n",
    "    ave = np.zeros(shape=(length, length, wide))\n",
    "\n",
    "    for i in range(0, length):\n",
    "        for j in range(i+1, length):\n",
    "            ave[i, j] = np.mean(feat[i: j+1], axis=0)\n",
    "            # print('i = %d, j = %d' % (i, j))\n",
    "\n",
    "    for i in range(0, length):\n",
    "        for j in range(i+1, length):\n",
    "            ave_one = ave[i, j]\n",
    "            dist_lst = [distance(ave_one, one) for one in feat[i: j+1]]\n",
    "            res[i, j] = sum(dist_lst)\n",
    "            # print('i = %d, j = %d' % (i, j))\n",
    "    return res\n",
    "\n",
    "def get_class_devide(dist_mat, class_num):\n",
    "    #  利用递推公式计算分成class_num类别的分割方法\n",
    "    length = len(dist_mat)\n",
    "    divided_point = np.zeros(shape=(length, class_num+1))  # 存切割点\n",
    "    diveded_dist = np.zeros(shape=(length, class_num+1))  # 存切割最小距离\n",
    "\n",
    "    for i in range(1, length):  # 分成两类\n",
    "        dist_lst = [dist_mat[0, k] + dist_mat[k+1, i] for k in range(0, i)]\n",
    "        divided_point[i, 2] = np.argmin(dist_lst)\n",
    "        diveded_dist[i, 2] = np.min(dist_lst)\n",
    "\n",
    "    for classes in range(3, class_num+1):   # 分成多类\n",
    "        for i in range(classes-1, length):\n",
    "            dist_lst = [diveded_dist[k, classes-1] + dist_mat[k+1, i] for k in range(classes-2, i)]  # 从n-1类到n类\n",
    "            divided_point[i, classes] = np.argmin(dist_lst) + classes - 2\n",
    "            diveded_dist[i, classes] = np.min(dist_lst)\n",
    "    return diveded_dist, divided_point\n",
    "\n",
    "def get_trace(trace_mat, class_num):\n",
    "    #  获得切割方法list，\n",
    "    #  trace_mat就是get_class_devide函数返回的divided_point，分割点记录矩阵\n",
    "    lst = []\n",
    "    length = len(trace_mat)  #length=38\n",
    "    pre = length - 1   #pre=37\n",
    "    for i in range(class_num, 1, -1):\n",
    "        temp = int(trace_mat[pre, i])\n",
    "        pre = temp\n",
    "        lst.append(temp)\n",
    "    lst.reverse()\n",
    "    return lst\n",
    "def get_one_essay_trace(feature,phrase_num):\n",
    "    #  整合调用 有序聚类方法\n",
    "    #  调用就可以获得一个文件的分割结果并存入本地\n",
    "\n",
    "    time_start = time.time()\n",
    "    dist_mat = get_dist_mat(feature)\n",
    "    phrase_num = phrase_num\n",
    "    min_dist_mat, min_trace_mat = get_class_devide(dist_mat, phrase_num)\n",
    "    # print(min_trace_mat)\n",
    "\n",
    "    lst = get_trace(min_trace_mat, phrase_num)\n",
    "    lst.append(len(feature))\n",
    "    print('划分结果为：',end='')\n",
    "    print(lst)\n",
    "    time_end = time.time()\n",
    "    print('cost time', time_end - time_start)\n",
    "    return lst,min_dist_mat,min_trace_mat\n",
    "def observe_divided(lst, sents):\n",
    "    # 展示分割结果\n",
    "    split_result=[]\n",
    "    start = 0\n",
    "    for end in lst:\n",
    "        cla_lst=[]\n",
    "        if end==len(sents):\n",
    "            end=end-1\n",
    "        for i in range(start, end+1):\n",
    "            cla_lst.append(sents[i])\n",
    "        start = end + 1\n",
    "        split_result.append(cla_lst)\n",
    "    return split_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T06:48:37.551866Z",
     "start_time": "2019-07-25T06:48:37.525028Z"
    }
   },
   "outputs": [],
   "source": [
    "class esPaperRetrieval():\n",
    "    '''\n",
    "    根据论文检索需求进行功能的微调\n",
    "    '''\n",
    "    _instance = None\n",
    "    _first_init = True\n",
    "    def __new__(cls, *args, **kw):\n",
    "        if not cls._instance:\n",
    "            cls._instance = super(esPaperRetrieval, cls).__new__(cls)  \n",
    "        return cls._instance\n",
    "    \n",
    "    def __init__(self, host, port):\n",
    "        '''\n",
    "        使用ES进行论文检索 指定host、port以及专利index之后进行检索\n",
    "        '''\n",
    "        super(esPaperRetrieval, self).__init__()\n",
    "        self.es = Elasticsearch(hosts=host, port=port, timeout=30, max_retries=10, retry_on_timeout=True)\n",
    "        self.indexName = 'paper-detail-index'\n",
    "\n",
    "    def do_search(self, titleQuery, kwordQuery, summaryQuery ,pubQuery,fromDate, toDate, volume):\n",
    "        '''\n",
    "        do_search方法执行具体检索过程\n",
    "        titleQuery 为对应标题检索词\n",
    "        kwordQuery 为对应关键字检索词\n",
    "        summaryQuery 为对应摘要检索词\n",
    "        上述三个词为or模式 可以出现 可以不出现\n",
    "        pubQuery 为对应文摘关键词 这个关键词必定匹配\n",
    "        fromDate 为检索字段起始日期 toDate为终结日期 日期格式 yyyy-mm-dd\n",
    "        volume为每次检索返回的数目\n",
    "        '''\n",
    "        queryBody = {\n",
    "          \"query\": {\n",
    "            \"bool\": {\n",
    "              \"should\": [\n",
    "                {\n",
    "                  \"term\": {\n",
    "                    \"P_Title\": titleQuery\n",
    "                  }\n",
    "                },\n",
    "                {\n",
    "                  \"term\": {\n",
    "                    \"P_Keyword\": kwordQuery\n",
    "                  }\n",
    "                },\n",
    "                {\n",
    "                  \"term\": {\n",
    "                    \"P_Summary\": summaryQuery\n",
    "                  }\n",
    "                },\n",
    "                  {\n",
    "                  \"term\": {\n",
    "                    \"P_Publication.keyword\": {\"value\":pubQuery}\n",
    "                  }\n",
    "                  }\n",
    "              ],\n",
    "              \"filter\": [\n",
    "                {\n",
    "                  \"range\": {\n",
    "                    \"P_year\": {\n",
    "                      \"gt\": fromDate,\n",
    "                      \"lt\": toDate\n",
    "                    }\n",
    "                  }\n",
    "                },\n",
    "              ]\n",
    "            }\n",
    "          },\n",
    "            \"from\": 0,\n",
    "            \"size\": volume,\n",
    "            \"sort\": [],\n",
    "            \"aggs\": {}\n",
    "        }\n",
    "#         print(queryBody)\n",
    "        result = self.es.search(index=self.indexName, body=queryBody)\n",
    "        return result\n",
    "\n",
    "    def format_search(self, result):\n",
    "        '''\n",
    "        format_search方法对检索结果进行格式化 构建符合要求的字段进行返回\n",
    "        输入result为检索结果 提取其中的检索结果进行后处理\n",
    "        使用ES检索后得到的结果中result['hits']['hits']为数组格式数据\n",
    "        其中每一个元素为一个dict 对应部分字段\n",
    "        '''\n",
    "        docs = result['hits']['hits']\n",
    "        docs = [i['_source'] for i in docs]\n",
    "        targetKeyList = 'P_ID, P_Title, P_Author, P_Publication, P_Organ, P_year, P_Keyword,     P_Summary, P_Keyword_seg, P_Title_seg,    P_Summary_seg, P_URL, P_Fields, P_Fields_two,P_References, P_Pagecount, P_Page, P_Language,    P_Download_num, P_Citation_num,P_Vector,P_Volume, P_Issue,P_Issn,P_Isbn, P_Doi,    P_Red1, P_Red2, P_Red3, P_Red4, P_Red5'\n",
    "        targetKeyList = [i.strip() for i in targetKeyList.split(',')]\n",
    "        dict_filter_by_keys = lambda d: {k: d[k] for k in targetKeyList}\n",
    "        dict_filter_text = lambda d: {k if not k == 'text' else 'claim_text': d[k] for k in d}\n",
    "        dict_filter_id = lambda d: {k if not k == '_id' else 'id': d[k] for k in d}\n",
    "        docs = (dict_filter_by_keys(doc) for doc in docs)\n",
    "        docs = [dict_filter_text(doc) for doc in docs]\n",
    "        return docs\n",
    "    def Retrieval(self, titleQuery, kwordQuery, summaryQuery ,pubQuery,fromDate, toDate, volume):\n",
    "        result = self.do_search(titleQuery, kwordQuery, summaryQuery ,pubQuery,fromDate, toDate, volume)\n",
    "        docs = self.format_search(result)\n",
    "        return docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 有序聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T06:48:39.622380Z",
     "start_time": "2019-07-25T06:48:38.687221Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d446eca5b1d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkeys_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"pub_id\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'algorithmName'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"title\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'className'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"publicationDate\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'topicName'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"firstApplicant\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'keywords'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myouxujulei\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'中医'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkeys_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-5fecda8ee9ac>\u001b[0m in \u001b[0;36myouxujulei\u001b[0;34m(key, n_class, n_top_topic)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;31m# 聚类数量\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_one_essay_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear_tfidf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0msplit_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobserve_divided\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myears_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-bae865e82f26>\u001b[0m in \u001b[0;36mget_one_essay_trace\u001b[0;34m(feature, phrase_num)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mdist_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dist_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mphrase_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphrase_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mmin_dist_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_trace_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_class_devide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphrase_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-bae865e82f26>\u001b[0m in \u001b[0;36mget_dist_mat\u001b[0;34m(feat)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#样本数量\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mwide\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#特征向量长度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwide\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "keys_map = {\"pub_id\":'algorithmName', \"title\":'className', \"publicationDate\":'topicName', \"firstApplicant\":'keywords'}\n",
    "\n",
    "result = youxujulei('中医')\n",
    "\n",
    "result = [{keys_map[k]:i[k] for k in i} for i in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主题聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T07:02:29.856271Z",
     "start_time": "2019-07-25T07:02:29.150462Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = zhutifenxi('中医',n_topic=7)\n",
    "\n",
    "result = [{'topicID':num,'topicWords':i} for num,i in enumerate(result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T07:02:30.420253Z",
     "start_time": "2019-07-25T07:02:30.391800Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'topicID': 0,\n",
       "  'topicWords': [{'name': '患者', 'value': 0.10833994910896118},\n",
       "   {'name': '认知损害', 'value': 0.11250992366344176},\n",
       "   {'name': '表达', 'value': 0.1},\n",
       "   {'name': '模型', 'value': 0.1},\n",
       "   {'name': '轻至', 'value': 0.1},\n",
       "   {'name': '治疗', 'value': 0.1828019029241683},\n",
       "   {'name': '起始', 'value': 0.10337595378660806},\n",
       "   {'name': '康复治疗', 'value': 0.11350381514643224},\n",
       "   {'name': '中线', 'value': 0.1},\n",
       "   {'name': '左旋多巴', 'value': 0.1},\n",
       "   {'name': '入院前', 'value': 0.12115633588735031},\n",
       "   {'name': '持续气道正压通气', 'value': 0.1},\n",
       "   {'name': '训练', 'value': 0.15289083971837575},\n",
       "   {'name': '中位', 'value': 0.11012786135982418},\n",
       "   {'name': '倾向', 'value': 0.6630529398843444},\n",
       "   {'name': '卡片', 'value': 0.12115633588735031},\n",
       "   {'name': '小脑后下动脉', 'value': 0.1},\n",
       "   {'name': 'bcl', 'value': 0.13036069773886172},\n",
       "   {'name': 'sanger测序', 'value': 0.12025572271964834},\n",
       "   {'name': '海人酸', 'value': 0.2297229812478637},\n",
       "   {'name': '顺利完成', 'value': 0.1041699745544806},\n",
       "   {'name': '临床', 'value': 0.11380031715402805},\n",
       "   {'name': 'mri扫描', 'value': 0.1},\n",
       "   {'name': '血管内', 'value': 0.18004183949336272},\n",
       "   {'name': '初级运动皮质', 'value': 0.1291898218813641},\n",
       "   {'name': '扣带回', 'value': 0.10337595378660806},\n",
       "   {'name': '药物', 'value': 0.10337595378660806},\n",
       "   {'name': '排列', 'value': 0.12115633588735031},\n",
       "   {'name': '起病', 'value': 0.10675190757321612},\n",
       "   {'name': '前交通动脉动脉瘤', 'value': 0.1}]},\n",
       " {'topicID': 1,\n",
       "  'topicWords': [{'name': '边界清楚', 'value': 0.14140095146208415},\n",
       "   {'name': '节细胞神经瘤', 'value': 0.1},\n",
       "   {'name': '前屈', 'value': 0.10833994910896118},\n",
       "   {'name': '磨除', 'value': 0.12084987277240294},\n",
       "   {'name': '动物模型', 'value': 0.12484057087725049},\n",
       "   {'name': '均为', 'value': 0.11667989821792235},\n",
       "   {'name': '发展', 'value': 0.1},\n",
       "   {'name': '反复发作', 'value': 0.1041699745544806},\n",
       "   {'name': '模拟', 'value': 0.1},\n",
       "   {'name': '结核病', 'value': 0.11656038058483367},\n",
       "   {'name': 'ftd', 'value': 0.11104025372322245},\n",
       "   {'name': '步态', 'value': 0.11104025372322245},\n",
       "   {'name': '中等', 'value': 0.1},\n",
       "   {'name': '岩骨', 'value': 0.1},\n",
       "   {'name': '甲基', 'value': 0.11667989821792235},\n",
       "   {'name': '尝试', 'value': 0.11104025372322245},\n",
       "   {'name': '血红蛋白', 'value': 0.1},\n",
       "   {'name': '描述', 'value': 0.10276006343080561},\n",
       "   {'name': '乙酰', 'value': 0.1041699745544806},\n",
       "   {'name': '方案', 'value': 0.1},\n",
       "   {'name': '继发性', 'value': 0.10337595378660806},\n",
       "   {'name': '典型', 'value': 0.1},\n",
       "   {'name': '表达变化', 'value': 0.10675190757321612},\n",
       "   {'name': '神经微丝蛋白', 'value': 0.1},\n",
       "   {'name': '总有效率', 'value': 0.11250992366344176},\n",
       "   {'name': '神经系统退行性疾病', 'value': 0.12084987277240294},\n",
       "   {'name': '原发性中枢神经系统淋巴瘤', 'value': 0.1264454198591879},\n",
       "   {'name': '测试成绩', 'value': 0.1},\n",
       "   {'name': 'cm', 'value': 0.1236316765062564},\n",
       "   {'name': '四肢', 'value': 0.10675190757321612}]},\n",
       " {'topicID': 2,\n",
       "  'topicWords': [{'name': '齿状突', 'value': 0.11250992366344176},\n",
       "   {'name': 'gd', 'value': 0.1},\n",
       "   {'name': 'mci', 'value': 0.1},\n",
       "   {'name': '事件', 'value': 0.10675190757321612},\n",
       "   {'name': '鸟嘌呤', 'value': 0.1},\n",
       "   {'name': '卵黄囊瘤', 'value': 0.10552012686161122},\n",
       "   {'name': '骨科', 'value': 0.1},\n",
       "   {'name': '波幅', 'value': 0.10337595378660806},\n",
       "   {'name': '生存期', 'value': 0.11104025372322245},\n",
       "   {'name': '密度', 'value': 0.14140095146208415},\n",
       "   {'name': '溶栓治疗', 'value': 0.1041699745544806},\n",
       "   {'name': '病理学特征', 'value': 0.1},\n",
       "   {'name': '美国', 'value': 0.1},\n",
       "   {'name': '功能', 'value': 0.10337595378660806},\n",
       "   {'name': '风险', 'value': 0.1041699745544806},\n",
       "   {'name': '世界', 'value': 0.11012786135982418},\n",
       "   {'name': '维生素b', 'value': 0.1264454198591879},\n",
       "   {'name': '远外侧入路', 'value': 0.1},\n",
       "   {'name': '静脉窦', 'value': 0.10833994910896118},\n",
       "   {'name': '统计', 'value': 0.1},\n",
       "   {'name': '节细胞神经瘤', 'value': 0.11656038058483367},\n",
       "   {'name': '癫痫', 'value': 0.1264454198591879},\n",
       "   {'name': '领域', 'value': 0.1},\n",
       "   {'name': '平均', 'value': 0.10337595378660806},\n",
       "   {'name': '生存', 'value': 0.1},\n",
       "   {'name': '托吡酯', 'value': 0.10552012686161122},\n",
       "   {'name': '非运动症状', 'value': 0.11656038058483367},\n",
       "   {'name': '周内', 'value': 0.1},\n",
       "   {'name': 'chiari畸形', 'value': 0.10337595378660806},\n",
       "   {'name': '神经系统退行性疾病', 'value': 0.1}]},\n",
       " {'topicID': 3,\n",
       "  'topicWords': [{'name': '免疫组织化学检测', 'value': 0.11250992366344176},\n",
       "   {'name': '比较差异', 'value': 0.1},\n",
       "   {'name': '青年', 'value': 0.11932044401563928},\n",
       "   {'name': '女性', 'value': 0.1},\n",
       "   {'name': '寰枕融合', 'value': 0.11250992366344176},\n",
       "   {'name': '通路', 'value': 0.11250992366344176},\n",
       "   {'name': '脑卒中高危人群', 'value': 0.10828019029241684},\n",
       "   {'name': '采用', 'value': 0.11350381514643224},\n",
       "   {'name': '高发', 'value': 0.10675190757321612},\n",
       "   {'name': '单一', 'value': 0.1041699745544806},\n",
       "   {'name': 'fa', 'value': 0.11932044401563928},\n",
       "   {'name': '关注', 'value': 0.1},\n",
       "   {'name': '左乙拉西坦', 'value': 0.10337595378660806},\n",
       "   {'name': '上升趋势', 'value': 0.1},\n",
       "   {'name': '失神发作', 'value': 0.1},\n",
       "   {'name': '扩散', 'value': 0.1291898218813641},\n",
       "   {'name': '生理', 'value': 0.1041699745544806},\n",
       "   {'name': '受体', 'value': 0.1},\n",
       "   {'name': '脑水肿', 'value': 0.10833994910896118},\n",
       "   {'name': '金标准', 'value': 0.11667989821792235},\n",
       "   {'name': 'atz', 'value': 0.1},\n",
       "   {'name': '痊愈', 'value': 0.1},\n",
       "   {'name': 'mwt', 'value': 0.11012786135982418},\n",
       "   {'name': '颈外动脉', 'value': 0.1},\n",
       "   {'name': 'ml', 'value': 0.1579613320469178},\n",
       "   {'name': '枕动脉', 'value': 0.10276006343080561},\n",
       "   {'name': '纹状体', 'value': 0.10552012686161122},\n",
       "   {'name': '降至', 'value': 0.10337595378660806},\n",
       "   {'name': '胶原', 'value': 0.1},\n",
       "   {'name': '纤维', 'value': 0.10675190757321612}]},\n",
       " {'topicID': 4,\n",
       "  'topicWords': [{'name': '结论', 'value': 0.1},\n",
       "   {'name': '每次', 'value': 0.1041699745544806},\n",
       "   {'name': '原发性中枢神经系统淋巴瘤', 'value': 0.1},\n",
       "   {'name': '视物模糊', 'value': 0.1},\n",
       "   {'name': '平衡功能', 'value': 0.1041699745544806},\n",
       "   {'name': '采用', 'value': 0.10552012686161122},\n",
       "   {'name': '肿瘤', 'value': 0.11667989821792235},\n",
       "   {'name': '重复', 'value': 0.10833994910896118},\n",
       "   {'name': '切除术', 'value': 0.1},\n",
       "   {'name': '周时', 'value': 0.11012786135982418},\n",
       "   {'name': '运动', 'value': 0.10828019029241684},\n",
       "   {'name': '目的分析', 'value': 0.1},\n",
       "   {'name': '症状性颅内出血', 'value': 0.1},\n",
       "   {'name': 'gos评分', 'value': 0.11687976893304028},\n",
       "   {'name': '桡动脉', 'value': 0.11932044401563928},\n",
       "   {'name': '寰椎', 'value': 0.1},\n",
       "   {'name': '成功率', 'value': 0.1},\n",
       "   {'name': '手术时间', 'value': 0.1},\n",
       "   {'name': '胶质瘤', 'value': 0.11687976893304028},\n",
       "   {'name': '各项', 'value': 0.11932044401563928},\n",
       "   {'name': '皮肤电传导', 'value': 0.276644059571559},\n",
       "   {'name': '青年', 'value': 0.10833994910896118},\n",
       "   {'name': '特征', 'value': 0.14140095146208415},\n",
       "   {'name': '争议', 'value': 0.10552012686161122},\n",
       "   {'name': '统计', 'value': 0.10552012686161122},\n",
       "   {'name': '调节', 'value': 0.11250992366344176},\n",
       "   {'name': 'ss', 'value': 0.11687976893304028},\n",
       "   {'name': '组织', 'value': 0.1579613320469178},\n",
       "   {'name': '生存时间', 'value': 0.10337595378660806},\n",
       "   {'name': '恶性肿瘤', 'value': 0.10337595378660806}]},\n",
       " {'topicID': 5,\n",
       "  'topicWords': [{'name': '成绩', 'value': 0.1},\n",
       "   {'name': '分级', 'value': 0.1},\n",
       "   {'name': '多导睡眠图监测', 'value': 0.1},\n",
       "   {'name': '持续气道正压通气', 'value': 0.12501984732688354},\n",
       "   {'name': 'mci', 'value': 0.11350381514643224},\n",
       "   {'name': '成人', 'value': 0.10276006343080561},\n",
       "   {'name': '规范', 'value': 0.1041699745544806},\n",
       "   {'name': '海人酸', 'value': 0.1},\n",
       "   {'name': '碰撞瘤', 'value': 0.10337595378660806},\n",
       "   {'name': '结扎', 'value': 0.10828019029241684},\n",
       "   {'name': '腹围', 'value': 0.1041699745544806},\n",
       "   {'name': '带来', 'value': 0.1},\n",
       "   {'name': '左乙拉西坦', 'value': 0.10828019029241684},\n",
       "   {'name': 'bbs', 'value': 0.1},\n",
       "   {'name': '星形胶质细胞', 'value': 0.1},\n",
       "   {'name': '肺部感染', 'value': 0.11667989821792235},\n",
       "   {'name': '功能区', 'value': 0.1},\n",
       "   {'name': '机械取栓', 'value': 0.11350381514643224},\n",
       "   {'name': '测验', 'value': 0.15817992369021333},\n",
       "   {'name': '部分性发作', 'value': 0.10675190757321612},\n",
       "   {'name': '代谢', 'value': 0.1041699745544806},\n",
       "   {'name': '构建', 'value': 0.1},\n",
       "   {'name': 'ftd', 'value': 0.1},\n",
       "   {'name': '神经变性', 'value': 0.10276006343080561},\n",
       "   {'name': '建议', 'value': 0.1},\n",
       "   {'name': '肿瘤全切除', 'value': 0.11250992366344176},\n",
       "   {'name': '万例', 'value': 0.1041699745544806},\n",
       "   {'name': '成功率', 'value': 0.1},\n",
       "   {'name': '核因子', 'value': 0.10276006343080561},\n",
       "   {'name': '率为', 'value': 0.11250992366344176}]},\n",
       " {'topicID': 6,\n",
       "  'topicWords': [{'name': '患侧', 'value': 0.11250992366344176},\n",
       "   {'name': '临床预后', 'value': 0.11350381514643224},\n",
       "   {'name': '分期', 'value': 0.1},\n",
       "   {'name': '发表', 'value': 0.10276006343080561},\n",
       "   {'name': '免疫表型', 'value': 0.10675190757321612},\n",
       "   {'name': '包含', 'value': 0.1},\n",
       "   {'name': '有效连接', 'value': 0.11687976893304028},\n",
       "   {'name': '节细胞胶质瘤', 'value': 0.10833994910896118},\n",
       "   {'name': '第四脑室', 'value': 0.13036069773886172},\n",
       "   {'name': '区域', 'value': 0.1236316765062564},\n",
       "   {'name': '原则', 'value': 0.10833994910896118},\n",
       "   {'name': '方式', 'value': 0.1},\n",
       "   {'name': '界限', 'value': 0.11667989821792235},\n",
       "   {'name': '康复训练', 'value': 0.10276006343080561},\n",
       "   {'name': '下肢麻木', 'value': 0.13173450383102545},\n",
       "   {'name': '再次手术', 'value': 0.10833994910896118},\n",
       "   {'name': '恶性肿瘤', 'value': 0.1},\n",
       "   {'name': '困难', 'value': 0.11012786135982418},\n",
       "   {'name': '后部', 'value': 0.10675190757321612},\n",
       "   {'name': '核内', 'value': 0.1041699745544806},\n",
       "   {'name': '多聚', 'value': 0.1},\n",
       "   {'name': '神经元', 'value': 0.12115633588735031},\n",
       "   {'name': '已知', 'value': 0.10833994910896118},\n",
       "   {'name': '环状强化', 'value': 0.10337595378660806},\n",
       "   {'name': '证实', 'value': 0.14140095146208415},\n",
       "   {'name': '丘脑', 'value': 0.1041699745544806},\n",
       "   {'name': '药物不良反应', 'value': 0.1},\n",
       "   {'name': '腓骨肌萎缩症', 'value': 0.11667989821792235},\n",
       "   {'name': '利用', 'value': 0.10833994910896118},\n",
       "   {'name': '卒中', 'value': 0.11104025372322245}]}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
