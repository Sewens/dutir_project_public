{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将检索模块和文本聚类模块进行封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T03:11:48.060808Z",
     "start_time": "2019-07-12T03:11:44.460628Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ES检索模块重构为一个对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T03:11:48.072871Z",
     "start_time": "2019-07-12T03:11:48.063759Z"
    }
   },
   "outputs": [],
   "source": [
    "class RetirevalMeta:\n",
    "    '''检索系统父类 定义三种方法\n",
    "    init部分负责检索服务器连接\n",
    "    do_search执行检索过程\n",
    "    format_search对检索结果进行格式化后处理\n",
    "    Retrieval将上述两种方法结合 返回最终结果\n",
    "    '''\n",
    "    def __init__(self,):\n",
    "        pass\n",
    "    def do_search(self,):\n",
    "        pass\n",
    "    def format_search(self,):\n",
    "        pass\n",
    "    def Retrieval(self,):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T03:11:48.148599Z",
     "start_time": "2019-07-12T03:11:48.075561Z"
    }
   },
   "outputs": [],
   "source": [
    "class esPatentRetrieval(RetirevalMeta):\n",
    "    def __init__(self,host,port):\n",
    "        '''\n",
    "        使用ES进行专利检索 指定host、port以及专利index之后进行检索\n",
    "        '''\n",
    "        super(esPatentRetrieval, self).__init__()\n",
    "        self.es = Elasticsearch(hosts=host,port=port,timeout=30, max_retries=10, retry_on_timeout=True)\n",
    "        self.indexName = 'patent-index'\n",
    "        \n",
    "    def do_search(self,query,fromDate,toDate,volume):\n",
    "        '''\n",
    "        do_search方法执行具体检索过程\n",
    "        query传入检索词 formDate和toDate分别为检索的前后时间\n",
    "        volume为返回文档数目\n",
    "        '''\n",
    "        queryKeywordDict = {\"match\": {\"text\": query}\n",
    "                }\n",
    "        queryDateRangeDict = {\"range\": {\n",
    "                    \"publicationDate\": {\n",
    "                      \"gt\": fromDate,\n",
    "                      \"lt\": toDate\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "        queryBody = {\"query\": {\"bool\": {\n",
    "              \"must\": [queryDateRangeDict,queryKeywordDict],\n",
    "              \"must_not\": [],\n",
    "              \"should\": []\n",
    "            }},\n",
    "          \"from\": 0,\n",
    "          \"size\": volume,\n",
    "          \"sort\": [],\n",
    "          \"aggs\": {}\n",
    "        }\n",
    "        result = self.es.search(index=self.indexName,body=queryBody)\n",
    "        return result\n",
    "    def format_search(self,result):\n",
    "        '''\n",
    "        format_search方法对检索结果进行格式化 构建符合要求的字段进行返回\n",
    "        输入result为检索结果 提取其中的检索结果进行后处理\n",
    "        使用ES检索后得到的结果中result['hits']['hits']为数组格式数据\n",
    "        其中每一个元素为一个dict 对应部分字段\n",
    "        '''\n",
    "        docs = result['hits']['hits']\n",
    "        docs = [i['_source'] for i in docs]\n",
    "        targetKeyList = 'id pub_id abstractDesc text examiner priorityDocNum agentName title applicationDocNum agentPersonName applicant ipcMain priorityDate inventor assignee publicationDate ipcList applicationDate firstApplicant'\n",
    "        targetKeyList = targetKeyList.split(' ')\n",
    "\n",
    "        dict_filter_by_keys = lambda d:{k:d[k] for k in targetKeyList}\n",
    "        dict_filter_text = lambda d:{k if not k=='text' else 'claim_text':d[k] for k in d}\n",
    "        dict_filter_id = lambda d:{k if not k=='_id' else 'id':d[k] for k in d}\n",
    "        \n",
    "        \n",
    "        docs = (dict_filter_by_keys(doc) for doc in docs)\n",
    "        docs = [dict_filter_text(doc) for doc in docs]\n",
    "        return docs\n",
    "    \n",
    "    def Retrieval(self,query,fromDate,toDate,volume):\n",
    "        result = self.do_search(query,fromDate,toDate,volume)\n",
    "        docs = self.format_search(result)\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T03:11:48.278591Z",
     "start_time": "2019-07-12T03:11:48.150744Z"
    }
   },
   "outputs": [],
   "source": [
    "es_obj = esPatentRetrieval(host='10.8.128.205',port=29200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T03:11:51.669626Z",
     "start_time": "2019-07-12T03:11:49.403923Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docs = es_obj.Retrieval('机器人','2000-01-06','2010-01-06',volume=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 客户端对于后端数据接口的访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T03:14:15.810156Z",
     "start_time": "2019-07-12T03:13:28.869650Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "body = {'searchQuery':'机器人',\n",
    "        'fromDate':'2000-06-02',\n",
    "        'toDate':'2016-01-01',\n",
    "        'volume':1000}\n",
    "\n",
    "baseUrl = 'http://10.8.128.205:29280/Lawbda/dataWare/1.0.0/patent/search'\n",
    "\n",
    "docs = requests.get(baseUrl,params=body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本聚类过程封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T12:15:35.773420Z",
     "start_time": "2019-07-10T12:15:35.470000Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T12:39:00.831975Z",
     "start_time": "2019-07-10T12:39:00.792763Z"
    }
   },
   "outputs": [],
   "source": [
    "class topicCluster():\n",
    "    def __init__(self,):\n",
    "        # 初始化分词器\n",
    "        self.tokenizer = lambda x:jieba.lcut(x)\n",
    "        self.tokenizer('我爱北京天安门')\n",
    "        # 读取向量化对象\n",
    "        self.tfidf_obj = self.load_pickle('../data/patent_data/model/patent_tfidf_model.pkl')\n",
    "        self.lda_obj = self.load_pickle('../data/patent_data/model/patent_lda_topic9_model.pkl')\n",
    "        # 读取关键词列表\n",
    "        self.keyword_df = pd.read_pickle('../data/patent_data/processed/claim_kword_df_tr4w.pkl')\n",
    "        kword_map = {i[2]:i[4] for i in self.keyword_df.itertuples()}\n",
    "        self.kword_map = {k:kword_map[k].split(' ') for k in kword_map}\n",
    "        \n",
    "    def data_wash(self,_str):\n",
    "        '''\n",
    "        数据清洗对象\n",
    "        '''\n",
    "        pattern_num = re.compile('\\d{4}\\.')\n",
    "        pattern_num1 = re.compile('\\d{1}\\.')\n",
    "        _str = re.sub(pattern_num,'',_str)\n",
    "        _str = re.sub(pattern_num1,'',_str)\n",
    "        return _str\n",
    "    \n",
    "    def do_cluster(self,texts,n_clusters):\n",
    "        '''\n",
    "        文本聚类对象\n",
    "        '''\n",
    "        km_obj = KMeans(n_clusters=n_clusters)\n",
    "        texts = [self.data_wash(i) for i in texts]\n",
    "        texts = [self.tokenizer(i) for i in texts]\n",
    "        texts = [' '.join(i) for i in texts]\n",
    "        tfidf_vec = self.tfidf_obj.transform(texts)\n",
    "        lda_vec = self.lda_obj.transform(tfidf_vec)\n",
    "        cluster_result = km_obj.fit_predict(lda_vec)\n",
    "        return cluster_result\n",
    "    \n",
    "    def do_kword(self,ids):\n",
    "        '''\n",
    "        由于预先对文本进行关键词抽取 因此只要传入对应文本id即可查表找到关键词\n",
    "        '''\n",
    "        kword_list = [self.kword_map[k] for k in ids]\n",
    "        return kword_list\n",
    "    \n",
    "    def do_format(self,cluster_wordtable):\n",
    "        '''\n",
    "        用于将输出结果格式化为API要求格式\n",
    "        '''\n",
    "        api_result = []\n",
    "        for topicID in cluster_wordtable:\n",
    "            temp_dict = {}\n",
    "            temp_dict['topicID'] = topicID\n",
    "            temp_dict['topicWords'] = []\n",
    "            for k in cluster_wordtable[topicID]:\n",
    "                temp_temp_dict = {}\n",
    "                temp_temp_dict['word'] = k\n",
    "                temp_temp_dict['freq'] = float(cluster_wordtable[topicID][k])\n",
    "                temp_dict['topicWords'].append(temp_temp_dict)\n",
    "            api_result.append(temp_dict)\n",
    "        return api_result\n",
    "    def Cluster(self,ids,texts,n_clusters):\n",
    "        '''\n",
    "        主方法 传入文本以及文本对应id \n",
    "        输出聚类后文本类别和对应关键词\n",
    "        如要求聚类数目为10 则输出\n",
    "        '''\n",
    "        cluster = self.do_cluster(texts,n_clusters)\n",
    "        kword = self.do_kword(ids)\n",
    "        topk = 20\n",
    "        cluster_wordtable = {}\n",
    "        for num,i in enumerate(cluster):\n",
    "            if not i in cluster_wordtable:\n",
    "                cluster_wordtable[i] = {}\n",
    "            kword_list = kword[num]\n",
    "            for word in kword_list:\n",
    "                if not word in cluster_wordtable[i]:\n",
    "                    cluster_wordtable[i][word] = 0\n",
    "                cluster_wordtable[i][word]+=1\n",
    "            cluster_wordtable[i] = {k:cluster_wordtable[i][k]for k in \n",
    "                                    sorted(cluster_wordtable[i],key=lambda x:cluster_wordtable[i][x],reverse=True)[:topk]}\n",
    "        final_result = self.do_format(cluster_wordtable)\n",
    "        return final_result\n",
    "    @staticmethod\n",
    "    def dump_pickle(obj,fname):\n",
    "        with open(fname,'wb') as file:\n",
    "            pickle.dump(obj,file)\n",
    "    @staticmethod\n",
    "    def load_pickle(fname):\n",
    "        return pickle.loads(open(fname,'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T12:39:06.671208Z",
     "start_time": "2019-07-10T12:39:02.190702Z"
    }
   },
   "outputs": [],
   "source": [
    "ppp = topicCluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T12:31:40.051988Z",
     "start_time": "2019-07-10T12:31:39.720606Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = [i['claim_text'] for i in docs.json()]\n",
    "ids = [i['pub_id'] for i in docs.json()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T12:39:15.601461Z",
     "start_time": "2019-07-10T12:39:07.927135Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster = ppp.Cluster(ids,texts,n_clusters=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T13:13:25.087406Z",
     "start_time": "2019-07-10T13:13:25.071756Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'topicID': 2,\n",
       "  'topicWords': [{'word': '包括', 'freq': 121},\n",
       "   {'word': '信息', 'freq': 72},\n",
       "   {'word': '用于', 'freq': 66},\n",
       "   {'word': '进行', 'freq': 57},\n",
       "   {'word': '接收', 'freq': 53},\n",
       "   {'word': '服务器', 'freq': 43},\n",
       "   {'word': '模块', 'freq': 34},\n",
       "   {'word': '权利', 'freq': 31},\n",
       "   {'word': '机器人', 'freq': 30},\n",
       "   {'word': '请求', 'freq': 18},\n",
       "   {'word': '在于', 'freq': 18},\n",
       "   {'word': '通信', 'freq': 17},\n",
       "   {'word': '客户端', 'freq': 15},\n",
       "   {'word': '消息', 'freq': 15},\n",
       "   {'word': '回复', 'freq': 2},\n",
       "   {'word': '群组', 'freq': 2},\n",
       "   {'word': '转发', 'freq': 2},\n",
       "   {'word': '群', 'freq': 1},\n",
       "   {'word': '组成员', 'freq': 1},\n",
       "   {'word': '将群', 'freq': 1}]},\n",
       " {'topicID': 3,\n",
       "  'topicWords': [{'word': '进行', 'freq': 95},\n",
       "   {'word': '机器人', 'freq': 94},\n",
       "   {'word': '图像', 'freq': 63},\n",
       "   {'word': '方法', 'freq': 51},\n",
       "   {'word': '时', 'freq': 44},\n",
       "   {'word': '计算', 'freq': 42},\n",
       "   {'word': '距离', 'freq': 19},\n",
       "   {'word': '产生', 'freq': 19},\n",
       "   {'word': '内', 'freq': 17},\n",
       "   {'word': '摄像机', 'freq': 14},\n",
       "   {'word': '目标', 'freq': 13},\n",
       "   {'word': '坐标', 'freq': 12},\n",
       "   {'word': '数字', 'freq': 9},\n",
       "   {'word': '接口', 'freq': 7},\n",
       "   {'word': '向量', 'freq': 4},\n",
       "   {'word': '全局', 'freq': 2},\n",
       "   {'word': '球', 'freq': 1},\n",
       "   {'word': '域', 'freq': 1},\n",
       "   {'word': 'ballx', 'freq': 1},\n",
       "   {'word': '捡球', 'freq': 1}]},\n",
       " {'topicID': 0,\n",
       "  'topicWords': [{'word': '机器人', 'freq': 106},\n",
       "   {'word': '控制', 'freq': 65},\n",
       "   {'word': '位置', 'freq': 46},\n",
       "   {'word': '方向', 'freq': 28},\n",
       "   {'word': '在于', 'freq': 24},\n",
       "   {'word': '运动', 'freq': 23},\n",
       "   {'word': '信息', 'freq': 20},\n",
       "   {'word': '距离', 'freq': 7},\n",
       "   {'word': '坐标系', 'freq': 6},\n",
       "   {'word': '视觉', 'freq': 5},\n",
       "   {'word': '时刻', 'freq': 4},\n",
       "   {'word': '得到', 'freq': 2},\n",
       "   {'word': '采样', 'freq': 2},\n",
       "   {'word': '跟随', 'freq': 1},\n",
       "   {'word': '领航', 'freq': 1},\n",
       "   {'word': 'copt', 'freq': 1},\n",
       "   {'word': '局部', 'freq': 1},\n",
       "   {'word': '预测', 'freq': 1},\n",
       "   {'word': '当前', 'freq': 1},\n",
       "   {'word': '原点', 'freq': 1}]},\n",
       " {'topicID': 1,\n",
       "  'topicWords': [{'word': '进行', 'freq': 36},\n",
       "   {'word': '信息', 'freq': 32},\n",
       "   {'word': '控制', 'freq': 25},\n",
       "   {'word': '方法', 'freq': 22},\n",
       "   {'word': '时', 'freq': 15},\n",
       "   {'word': '步骤', 'freq': 13},\n",
       "   {'word': '具有', 'freq': 12},\n",
       "   {'word': '位置', 'freq': 10},\n",
       "   {'word': '采集', 'freq': 7},\n",
       "   {'word': '动作', 'freq': 6},\n",
       "   {'word': '人', 'freq': 6},\n",
       "   {'word': '作业', 'freq': 4},\n",
       "   {'word': '值', 'freq': 3},\n",
       "   {'word': '设定', 'freq': 3},\n",
       "   {'word': '手臂', 'freq': 2},\n",
       "   {'word': '粘性', 'freq': 1},\n",
       "   {'word': '家庭', 'freq': 1},\n",
       "   {'word': '工序', 'freq': 1},\n",
       "   {'word': '成为', 'freq': 1},\n",
       "   {'word': '控制参数', 'freq': 1}]},\n",
       " {'topicID': 4,\n",
       "  'topicWords': [{'word': '机器人', 'freq': 200},\n",
       "   {'word': '连接', 'freq': 124},\n",
       "   {'word': '特征', 'freq': 110},\n",
       "   {'word': '装置', 'freq': 92},\n",
       "   {'word': '旋转', 'freq': 63},\n",
       "   {'word': '控制', 'freq': 57},\n",
       "   {'word': '单元', 'freq': 33},\n",
       "   {'word': '模块', 'freq': 13},\n",
       "   {'word': '机', 'freq': 7},\n",
       "   {'word': '自动', 'freq': 6},\n",
       "   {'word': '传递', 'freq': 5},\n",
       "   {'word': 'plc', 'freq': 2},\n",
       "   {'word': '分支', 'freq': 2},\n",
       "   {'word': '站', 'freq': 2},\n",
       "   {'word': '总线', 'freq': 2},\n",
       "   {'word': '包边', 'freq': 1},\n",
       "   {'word': 'cs1d', 'freq': 1},\n",
       "   {'word': 'device', 'freq': 1},\n",
       "   {'word': '操纵箱', 'freq': 1},\n",
       "   {'word': 'net', 'freq': 1}]}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 时序聚类过程的封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T13:09:48.377303Z",
     "start_time": "2019-07-10T13:09:48.370569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T13:10:43.119277Z",
     "start_time": "2019-07-10T13:10:43.115401Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-10T13:10:49.546739Z",
     "start_time": "2019-07-10T13:10:49.540792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.1'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
