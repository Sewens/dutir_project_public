{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T03:24:28.899074Z",
     "start_time": "2019-07-22T03:24:27.056150Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import re,time\n",
    "\n",
    "#导入PCA算法库\n",
    "from textrank4zh import TextRank4Keyword, TextRank4Sentence\n",
    "from sklearn import ensemble\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import ensemble\n",
    "from sklearn.externals import joblib\n",
    "from elasticsearch import Elasticsearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T03:24:28.922384Z",
     "start_time": "2019-07-22T03:24:28.902239Z"
    }
   },
   "outputs": [],
   "source": [
    "def distance(a, b):\n",
    "    #  计算两个vector的距离，逐项差的平方和，不开根号\n",
    "    if len(a) != len(b):\n",
    "        print('wrong')\n",
    "        return 0\n",
    "    else:\n",
    "        temp = a - b\n",
    "        temp = temp ** 2\n",
    "        res = sum(temp)\n",
    "        return res\n",
    "def get_dist_mat(feat):\n",
    "    #  输入为特征矩阵，返回一个相似度矩阵（行数乘行数）\n",
    "    print(type(feat))\n",
    "    length=feat.shape[0]#样本数量\n",
    "    wide = feat.shape[1]#特征向量长度\n",
    "    res = np.zeros(shape=(length, length))\n",
    "    ave = np.zeros(shape=(length, length, wide))\n",
    "\n",
    "    for i in range(0, length):\n",
    "        for j in range(i+1, length):\n",
    "            ave[i, j] = np.mean(feat[i: j+1], axis=0)\n",
    "            # print('i = %d, j = %d' % (i, j))\n",
    "\n",
    "    for i in range(0, length):\n",
    "        for j in range(i+1, length):\n",
    "            ave_one = ave[i, j]\n",
    "            dist_lst = [distance(ave_one, one) for one in feat[i: j+1]]\n",
    "            res[i, j] = sum(dist_lst)\n",
    "            # print('i = %d, j = %d' % (i, j))\n",
    "    return res\n",
    "\n",
    "def get_class_devide(dist_mat, class_num):\n",
    "    #  利用递推公式计算分成class_num类别的分割方法\n",
    "    length = len(dist_mat)\n",
    "    divided_point = np.zeros(shape=(length, class_num+1))  # 存切割点\n",
    "    diveded_dist = np.zeros(shape=(length, class_num+1))  # 存切割最小距离\n",
    "\n",
    "    for i in range(1, length):  # 分成两类\n",
    "        dist_lst = [dist_mat[0, k] + dist_mat[k+1, i] for k in range(0, i)]\n",
    "        divided_point[i, 2] = np.argmin(dist_lst)\n",
    "        diveded_dist[i, 2] = np.min(dist_lst)\n",
    "\n",
    "    for classes in range(3, class_num+1):   # 分成多类\n",
    "        for i in range(classes-1, length):\n",
    "            dist_lst = [diveded_dist[k, classes-1] + dist_mat[k+1, i] for k in range(classes-2, i)]  # 从n-1类到n类\n",
    "            divided_point[i, classes] = np.argmin(dist_lst) + classes - 2\n",
    "            diveded_dist[i, classes] = np.min(dist_lst)\n",
    "    return diveded_dist, divided_point\n",
    "\n",
    "def get_trace(trace_mat, class_num):\n",
    "    #  获得切割方法list，\n",
    "    #  trace_mat就是get_class_devide函数返回的divided_point，分割点记录矩阵\n",
    "    lst = []\n",
    "    length = len(trace_mat)  #length=38\n",
    "    pre = length - 1   #pre=37\n",
    "    for i in range(class_num, 1, -1):\n",
    "        temp = int(trace_mat[pre, i])\n",
    "        pre = temp\n",
    "        lst.append(temp)\n",
    "    lst.reverse()\n",
    "    return lst\n",
    "def get_one_essay_trace(feature,phrase_num):\n",
    "    #  整合调用 有序聚类方法\n",
    "    #  调用就可以获得一个文件的分割结果并存入本地\n",
    "\n",
    "    time_start = time.time()\n",
    "    dist_mat = get_dist_mat(feature)\n",
    "    phrase_num = phrase_num\n",
    "    min_dist_mat, min_trace_mat = get_class_devide(dist_mat, phrase_num)\n",
    "    # print(min_trace_mat)\n",
    "\n",
    "    lst = get_trace(min_trace_mat, phrase_num)\n",
    "    lst.append(len(feature))\n",
    "    print('划分结果为：',end='')\n",
    "    print(lst)\n",
    "    time_end = time.time()\n",
    "    print('cost time', time_end - time_start)\n",
    "    return lst,min_dist_mat,min_trace_mat\n",
    "def observe_divided(lst, sents):\n",
    "    # 展示分割结果\n",
    "    split_result=[]\n",
    "    start = 0\n",
    "    for end in lst:\n",
    "        cla_lst=[]\n",
    "        if end==len(sents):\n",
    "            end=end-1\n",
    "        for i in range(start, end+1):\n",
    "            cla_lst.append(sents[i])\n",
    "        start = end + 1\n",
    "        split_result.append(cla_lst)\n",
    "    return split_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T03:24:29.062848Z",
     "start_time": "2019-07-22T03:24:28.924232Z"
    }
   },
   "outputs": [],
   "source": [
    "class esPaperRetrieval():\n",
    "    '''\n",
    "    根据论文检索需求进行功能的微调\n",
    "    '''\n",
    "    _instance = None\n",
    "    _first_init = True\n",
    "    def __new__(cls, *args, **kw):\n",
    "        if not cls._instance:\n",
    "            cls._instance = super(esPaperRetrieval, cls).__new__(cls)\n",
    "        return cls._instance\n",
    "\n",
    "    def __init__(self, host, port):\n",
    "        '''\n",
    "        使用ES进行论文检索 指定host、port以及专利index之后进行检索\n",
    "        '''\n",
    "        super(esPaperRetrieval, self).__init__()\n",
    "        self.es = Elasticsearch(hosts=host, port=port, timeout=30, max_retries=10, retry_on_timeout=True)\n",
    "        self.indexName = 'paper-detail-index'\n",
    "\n",
    "    def do_search(self, titleQuery, kwordQuery, summaryQuery ,pubQuery,fromDate, toDate, volume):\n",
    "        '''\n",
    "        do_search方法执行具体检索过程\n",
    "        titleQuery 为对应标题检索词\n",
    "        kwordQuery 为对应关键字检索词\n",
    "        summaryQuery 为对应摘要检索词\n",
    "        上述三个词为or模式 可以出现 可以不出现\n",
    "        pubQuery 为对应文摘关键词 这个关键词必定匹配\n",
    "        fromDate 为检索字段起始日期 toDate为终结日期 日期格式 yyyy-mm-dd\n",
    "        volume为每次检索返回的数目\n",
    "        '''\n",
    "        queryBody = {\n",
    "          \"query\": {\n",
    "            \"bool\": {\n",
    "              \"should\": [\n",
    "                {\n",
    "                  \"term\": {\n",
    "                    \"P_Title\": titleQuery\n",
    "                  }\n",
    "                },\n",
    "                {\n",
    "                  \"term\": {\n",
    "                    \"P_Keyword\": kwordQuery\n",
    "                  }\n",
    "                },\n",
    "                {\n",
    "                  \"term\": {\n",
    "                    \"P_Summary\": summaryQuery\n",
    "                  }\n",
    "                },\n",
    "                  {\n",
    "                  \"term\": {\n",
    "                    \"P_Publication.keyword\": {\"value\":pubQuery}\n",
    "                  }\n",
    "                  }\n",
    "              ],\n",
    "              \"filter\": [\n",
    "                {\n",
    "                  \"range\": {\n",
    "                    \"P_year\": {\n",
    "                      \"gt\": fromDate,\n",
    "                      \"lt\": toDate\n",
    "                    }\n",
    "                  }\n",
    "                },\n",
    "              ]\n",
    "            }\n",
    "          },\n",
    "            \"from\": 0,\n",
    "            \"size\": volume,\n",
    "            \"sort\": [],\n",
    "            \"aggs\": {}\n",
    "        }\n",
    "#         print(queryBody)\n",
    "        result = self.es.search(index=self.indexName, body=queryBody)\n",
    "        return result\n",
    "\n",
    "    def format_search(self, result):\n",
    "        '''\n",
    "        format_search方法对检索结果进行格式化 构建符合要求的字段进行返回\n",
    "        输入result为检索结果 提取其中的检索结果进行后处理\n",
    "        使用ES检索后得到的结果中result['hits']['hits']为数组格式数据\n",
    "        其中每一个元素为一个dict 对应部分字段\n",
    "        '''\n",
    "        docs = result['hits']['hits']\n",
    "        docs = [i['_source'] for i in docs]\n",
    "        targetKeyList = 'P_ID, P_Title, P_Author, P_Publication, P_Organ, P_year, P_Keyword, \\\n",
    "    P_Summary, P_Keyword_seg, P_Title_seg,\\\n",
    "    P_Summary_seg, P_URL, P_Fields, P_Fields_two,P_References, P_Pagecount, P_Page, P_Language,\\\n",
    "    P_Download_num, P_Citation_num,P_Vector,P_Volume, P_Issue,P_Issn,P_Isbn, P_Doi,\\\n",
    "    P_Red1, P_Red2, P_Red3, P_Red4, P_Red5'\n",
    "        targetKeyList = [i.strip() for i in targetKeyList.split(',')]\n",
    "        dict_filter_by_keys = lambda d: {k: d[k] for k in targetKeyList}\n",
    "        dict_filter_text = lambda d: {k if not k == 'text' else 'claim_text': d[k] for k in d}\n",
    "        dict_filter_id = lambda d: {k if not k == '_id' else 'id': d[k] for k in d}\n",
    "        docs = (dict_filter_by_keys(doc) for doc in docs)\n",
    "        docs = [dict_filter_text(doc) for doc in docs]\n",
    "        return docs\n",
    "    def Retrieval(self, titleQuery, kwordQuery, summaryQuery ,pubQuery,fromDate, toDate, volume):\n",
    "        result = self.do_search(titleQuery, kwordQuery, summaryQuery ,pubQuery,fromDate, toDate, volume)\n",
    "        docs = self.format_search(result)\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T07:32:43.283043Z",
     "start_time": "2019-07-22T07:32:43.194337Z"
    }
   },
   "outputs": [],
   "source": [
    "class pre_word_count():\n",
    "    def __init__(self,data_path,model_path,hotword_num):\n",
    "        self.data = pd.read_json(data_path)\n",
    "        self.data['authors_seg'] = self.data.apply(lambda r: r['P_Red1'] + r['P_Red3'],axis=1)\n",
    "        self.data['year'] = self.data['P_year'].apply(lambda x:x[:4])\n",
    "        self.model_path = model_path\n",
    "        self.hotword_num = hotword_num\n",
    "    # 统计出现在句子中的词频\n",
    "    def tf(self,word,sentence):\n",
    "        c=0\n",
    "        s=sentence.split()\n",
    "        for i in s:\n",
    "            if word==i:\n",
    "                c+=1\n",
    "        return c\n",
    "\n",
    "    # 统计非重复的所有作者\n",
    "    def tongjiau(self,li):\n",
    "        authors=[]\n",
    "        for i in li:\n",
    "            try:\n",
    "                authors+=i.split()\n",
    "            except:\n",
    "                continue\n",
    "        return list(set(authors))\n",
    "\n",
    "    # 判断新作者是否在论文中提及热点词\n",
    "    def mention(self,authors,word,sentences,senten_auth):\n",
    "        i=0\n",
    "        for a in authors:\n",
    "            for j in range(len(sentences)):\n",
    "                try:\n",
    "                    if len(list(set(a).intersection(set(senten_auth[j]))))>0 and word in sentences[j]:\n",
    "                        i+=1\n",
    "                except:\n",
    "                    continue\n",
    "        return i\n",
    "\n",
    "    # 统计某个热点词在某年的不同期刊的提及数\n",
    "    def multi_journal(self,word,sentences,journals):\n",
    "        men_journal=[]\n",
    "        for j in range(len(sentences)):\n",
    "            try:\n",
    "                if word in sentences[j]:\n",
    "                    men_journal.append(journals[j])\n",
    "            except:\n",
    "                continue\n",
    "        s=set(men_journal)\n",
    "        if None in s:\n",
    "            s.remove(None)\n",
    "        return len(s)\n",
    "\n",
    "    # 抽取词频特征\n",
    "    def feature(self,word,year_df):\n",
    "        abstract_tf=[]\n",
    "        keyword_tf=[]\n",
    "        for y in list(year_df['seg_abstract']):\n",
    "            abstract_tf.append(self.tf(word,y))\n",
    "        for i in list(year_df['seg_keywords']):\n",
    "            keyword_tf.append(self.tf(word,i))\n",
    "        return abstract_tf,keyword_tf\n",
    "\n",
    "    #计算list的平均数\n",
    "\n",
    "    def pingjun(self,L):\n",
    "        if len(L)==0:\n",
    "            return 0\n",
    "        else:\n",
    "            s=0\n",
    "            for i in L:\n",
    "                s+=i\n",
    "\n",
    "            return int(s/len(L))\n",
    "    # 获取热点词\n",
    "    def get_hotwords(self,hotword_num):\n",
    "        guanjian=' '.join(list(self.data['P_Keyword_seg'])).split()\n",
    "        #textrank方法获取关键词\n",
    "        \n",
    "        #merge=' '.join(guanjian)\n",
    "        #tr4w = TextRank4Keyword()\n",
    "        #tr4w.analyze(text=merge, window=4)\n",
    "        #pred_words=[]\n",
    "        #for item in tr4w.get_keywords(hotword_num, word_min_len=2):\n",
    "            #pred_words.append(item.word)\n",
    "        #根据词频排序获取关键词\n",
    "        result = Counter(guanjian)\n",
    "        d = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "        pred_words=list(map(lambda x:x[0],d))[:hotword_num]\n",
    "        return pred_words\n",
    "    # 统计每年发表的论文数\n",
    "    def year_paper_num(self,):\n",
    "        year_num=[]\n",
    "        years=list(set(self.data['year']))\n",
    "        group_df=self.data.groupby(by=['year'])\n",
    "        # years.remove(None)\n",
    "        years=sorted([int(i) for i in years])\n",
    "        for y in years:\n",
    "            try:\n",
    "                year_num.append(len(group_df.get_group(str(y))))\n",
    "            except:\n",
    "                continue\n",
    "        return group_df,years,year_num\n",
    "    # 按年份将摘要整合\n",
    "    def groupby_year(self,group_df,years,year_num):\n",
    "        years_df=pd.DataFrame()\n",
    "        years_df['year']=years\n",
    "        seg,key,tit,jou,authors=[],[],[],[],[]\n",
    "\n",
    "        for i in years:\n",
    "            seg.append(' '.join(group_df.get_group(str(i))['P_Summary_seg']))\n",
    "            k=group_df.get_group(str(i))['P_Keyword_seg']\n",
    "            key.append(' '.join(k))\n",
    "            tit.append(' '.join(group_df.get_group(str(i))['P_Title_seg']))\n",
    "            jou.append(' '.join(group_df.get_group(str(i))['P_Publication']))\n",
    "            authors.append(self.tongjiau(group_df.get_group(str(i))['authors_seg']))\n",
    "        years_df['seg_abstract'] = seg\n",
    "        years_df['seg_keywords'] = key\n",
    "        years_df['seg_title'] = tit\n",
    "        years_df['seg_authors'] = authors\n",
    "        years_df['Jounal'] = jou\n",
    "        years_df['paper_num'] = year_num\n",
    "        return years_df\n",
    "    # 统计每年的新作者\n",
    "    def year_new_author(self,years_df):\n",
    "        authors = list(years_df['seg_authors'])\n",
    "        new_author = [authors[0]]\n",
    "        for i in range(1,len(years_df)):\n",
    "            new=[]\n",
    "            for j in authors[i]:\n",
    "                if j not in authors[i-1]:\n",
    "                    new.append(j)\n",
    "            new_author.append(new)\n",
    "        return new_author\n",
    "    # 统计每年新作者提及数\n",
    "    def year_new_author_mention(self,pred_words,new_author,years):\n",
    "        newauthor_mens=[]\n",
    "        group_df=self.data.groupby(by=['year'])\n",
    "        for word in pred_words:\n",
    "            for i in range(len(new_author)):\n",
    "                newauthor_men=self.mention(new_author,word,list(group_df.get_group(str(years[i]))['P_Summary']),\\\n",
    "                                           list(map(lambda x:x.split(),list(group_df.get_group(str(years[i]))['authors_seg']))))\n",
    "                newauthor_mens.append(newauthor_men)\n",
    "        return newauthor_mens\n",
    "    # 统计跨学科提及数\n",
    "    def multi_sub(self,pred_words,years):\n",
    "        multi_mens = []\n",
    "        group_df = self.data.groupby(by=['year'])\n",
    "        for word in pred_words:\n",
    "            for i in range(len(years)):\n",
    "\n",
    "                journals=self.multi_journal(word,list(group_df.get_group(str(years[i]))['P_Summary']),\\\n",
    "                                            list(group_df.get_group(str(years[i]))['P_Publication']))\n",
    "                multi_mens.append(journals)\n",
    "        return multi_mens\n",
    "    # 统计每个词初次在关键词中出现的年份\n",
    "    def first_year(self,pred_words,years_df):\n",
    "        f_year=[]\n",
    "        pp=[]\n",
    "        for w in range(len(pred_words)):\n",
    "            for y,i in zip(list(years_df['year']),list(years_df['seg_keywords'])):\n",
    "                if pred_words[w] in i:\n",
    "                    f_year.append(y)\n",
    "                    pp.append(w)\n",
    "                    break\n",
    "        return f_year\n",
    "    #获取每个词18年的特征\n",
    "    def get_feature(self,years_df,pred_words,f_year,newauthor_mens,multi_mens):\n",
    "        year_num=len(years_df)\n",
    "        pp=pd.DataFrame()\n",
    "        for i in range(len(pred_words)):\n",
    "            word=pred_words[i]\n",
    "            fyear=f_year[i]\n",
    "            exist_year=[]\n",
    "            for n,f in zip(list(years_df['year']),[fyear]*year_num):\n",
    "                e=n-f\n",
    "                if e<0:\n",
    "                    exist_year.append(0)\n",
    "                else:\n",
    "                    exist_year.append(e)\n",
    "            dd=pd.DataFrame()\n",
    "            dd['word']=[word]*year_num\n",
    "            dd['f1']=self.feature(word,years_df)[0]\n",
    "            dd['f2']=self.feature(word,years_df)[1]\n",
    "            dd['f3'] = exist_year\n",
    "            dd['f4'] = newauthor_mens[i*year_num:i*year_num+(year_num-1)]+\\\n",
    "            [self.pingjun(newauthor_mens[i*year_num+(year_num-1)-3:i*year_num+(year_num-1)])]\n",
    "\n",
    "            dd['f6'] = multi_mens[i*year_num:i*year_num+(year_num-1)]+\\\n",
    "            [self.pingjun(multi_mens[i*year_num+(year_num-1)-3:i*year_num+(year_num-1)])]\n",
    "\n",
    "            if i==0:\n",
    "                pp=dd\n",
    "            else:\n",
    "                pp=pp.append(dd)\n",
    "        pp=pp.reset_index(drop=True)\n",
    "        return pp\n",
    "    #预测某个词的词频\n",
    "    def zhidingword(self,search_word,test_data,model):\n",
    "        pre_data=test_data.loc[test_data.word==search_word].iloc[:,1:]\n",
    "        result = model.predict(pre_data)\n",
    "        return int(result)\n",
    "    #返回结果\n",
    "    def pre_result(self):\n",
    "        model_GBR=joblib.load(self.model_path)\n",
    "        pred_words=self.get_hotwords(self.hotword_num)\n",
    "        years=self.year_paper_num()[1]\n",
    "        group_df=self.year_paper_num()[0]\n",
    "        year_num=self.year_paper_num()[2]\n",
    "        years_df=self.groupby_year(group_df,years,year_num)\n",
    "        f_year=self.first_year(pred_words,years_df)\n",
    "        new_author=self.year_new_author(years_df)\n",
    "        newauthor_mens=self.year_new_author_mention(pred_words,new_author,years)\n",
    "        multi_mens=self.multi_sub(pred_words,years)\n",
    "        pp=self.get_feature(years_df,pred_words,f_year,newauthor_mens,multi_mens)\n",
    "\n",
    "        num=list(range(len(years)-1,len(years)*self.hotword_num,len(years)))\n",
    "        test_data=pp.iloc[num]\n",
    "        all_wordtf=[]\n",
    "        for word in pred_words:\n",
    "            result=self.zhidingword(word,test_data,model_GBR)\n",
    "            search_ke=list(pp.loc[pp.word==word]['f1'])+[result]\n",
    "            all_wordtf.extend(search_ke)\n",
    "        result=pd.DataFrame()\n",
    "        years.append(years[-1]+1)\n",
    "        result['word']=pred_words*len(years)\n",
    "        result['year']=years*len(pred_words)\n",
    "        result['count']=all_wordtf\n",
    "        \n",
    "        word_2019=result.loc[result['year']==2019]\n",
    "        word_2019_new = word_2019.sort_values(by=\"count\",ascending=False)\n",
    "        Top_hot_word=list(word_2019_new.loc[result['year']==2019]['word'])\n",
    "\n",
    "        hot_year=list(years)\n",
    "        freq_word=[]\n",
    "        freq=[]\n",
    "        freqs=[]\n",
    "        for www in Top_hot_word:\n",
    "            freq_word.append(www)\n",
    "            freq=list(result.loc[result['word']==www].sort_values(by=\"year\",ascending=True)['count'])\n",
    "            freqs.append(freq)\n",
    "        draw=pd.DataFrame()\n",
    "        draw[\"draw_word\"]=freq_word\n",
    "        draw[\"draw_freqs\"]=freqs\n",
    "        draw_dict = [{'draw_word':i[1],'draw_freqs':i[2]} for i in draw.itertuples()]\n",
    "#         draw_json=draw.to_json(orient='index')\n",
    "        altm = {'topnn':Top_hot_word,'year':hot_year, 'draw':draw_dict}\n",
    "        return altm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T07:51:57.809149Z",
     "start_time": "2019-07-22T07:51:57.722380Z"
    }
   },
   "outputs": [],
   "source": [
    "class pre_word_count1():\n",
    "    def __init__(self, data_path, model_path, hotword_num):\n",
    "        self.data = pd.read_json(data_path)\n",
    "        self.data['authors_seg'] = self.data.apply(lambda r: r['P_Red1'] + r['P_Red3'], axis=1)\n",
    "        self.data['year'] = self.data['P_year'].apply(lambda x: x[:4])\n",
    "        self.model_path = model_path\n",
    "        self.hotword_num = hotword_num\n",
    "\n",
    "    # 统计出现在句子中的词频\n",
    "    def tf(self, word, sentence):\n",
    "        c = 0\n",
    "        s = sentence.split()\n",
    "        for i in s:\n",
    "            if word == i:\n",
    "                c += 1\n",
    "        return c\n",
    "\n",
    "    # 统计非重复的所有作者\n",
    "    def tongjiau(self, li):\n",
    "        authors = []\n",
    "        for i in li:\n",
    "            try:\n",
    "                authors += i.split()\n",
    "            except:\n",
    "                continue\n",
    "        return list(set(authors))\n",
    "\n",
    "    # 判断新作者是否在论文中提及热点词\n",
    "    def mention(self, authors, word, sentences, senten_auth):\n",
    "        i = 0\n",
    "        for a in authors:\n",
    "            for j in range(len(sentences)):\n",
    "                try:\n",
    "                    if len(list(set(a).intersection(set(senten_auth[j])))) > 0 and word in sentences[j]:\n",
    "                        i += 1\n",
    "                except:\n",
    "                    continue\n",
    "        return i\n",
    "\n",
    "    # 统计某个热点词在某年的不同期刊的提及数\n",
    "    def multi_journal(self, word, sentences, journals):\n",
    "        men_journal = []\n",
    "        for j in range(len(sentences)):\n",
    "            try:\n",
    "                if word in sentences[j]:\n",
    "                    men_journal.append(journals[j])\n",
    "            except:\n",
    "                continue\n",
    "        s = set(men_journal)\n",
    "        if None in s:\n",
    "            s.remove(None)\n",
    "        return len(s)\n",
    "\n",
    "    # 抽取词频特征\n",
    "    def feature(self, word, year_df):\n",
    "        abstract_tf = []\n",
    "        keyword_tf = []\n",
    "        for y in list(year_df['seg_abstract']):\n",
    "            abstract_tf.append(self.tf(word, y))\n",
    "        for i in list(year_df['seg_keywords']):\n",
    "            keyword_tf.append(self.tf(word, i))\n",
    "        return abstract_tf, keyword_tf\n",
    "\n",
    "    # 计算list的平均数\n",
    "\n",
    "    def pingjun(self, L):\n",
    "        if len(L) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            s = 0\n",
    "            for i in L:\n",
    "                s += i\n",
    "\n",
    "            return int(s / len(L))\n",
    "\n",
    "    # 获取热点词\n",
    "    def get_hotwords(self, hotword_num):\n",
    "        guanjian = ' '.join(list(self.data['P_Keyword_seg'])).split()\n",
    "        # textrank方法获取关键词\n",
    "\n",
    "        # merge=' '.join(guanjian)\n",
    "        # tr4w = TextRank4Keyword()\n",
    "        # tr4w.analyze(text=merge, window=4)\n",
    "        # pred_words=[]\n",
    "        # for item in tr4w.get_keywords(hotword_num, word_min_len=2):\n",
    "        # pred_words.append(item.word)\n",
    "        # 根据词频排序获取关键词\n",
    "        result = Counter(guanjian)\n",
    "        d = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "        pred_words = list(map(lambda x: x[0], d))[:hotword_num]\n",
    "        return pred_words\n",
    "\n",
    "    # 统计每年发表的论文数\n",
    "    def year_paper_num(self, ):\n",
    "        year_num = []\n",
    "        years = list(set(self.data['year']))\n",
    "        group_df = self.data.groupby(by=['year'])\n",
    "        # years.remove(None)\n",
    "        years = sorted([int(i) for i in years])\n",
    "        for y in years:\n",
    "            try:\n",
    "                year_num.append(len(group_df.get_group(str(y))))\n",
    "            except:\n",
    "                continue\n",
    "        return group_df, years, year_num\n",
    "\n",
    "    # 按年份将摘要整合\n",
    "    def groupby_year(self, group_df, years, year_num):\n",
    "        years_df = pd.DataFrame()\n",
    "        years_df['year'] = years\n",
    "        seg, key, tit, jou, authors = [], [], [], [], []\n",
    "\n",
    "        for i in years:\n",
    "            seg.append(' '.join(group_df.get_group(str(i))['P_Summary_seg']))\n",
    "            k = group_df.get_group(str(i))['P_Keyword_seg']\n",
    "            key.append(' '.join(k))\n",
    "            tit.append(' '.join(group_df.get_group(str(i))['P_Title_seg']))\n",
    "            jou.append(' '.join(group_df.get_group(str(i))['P_Publication']))\n",
    "            authors.append(self.tongjiau(group_df.get_group(str(i))['authors_seg']))\n",
    "        years_df['seg_abstract'] = seg\n",
    "        years_df['seg_keywords'] = key\n",
    "        years_df['seg_title'] = tit\n",
    "        years_df['seg_authors'] = authors\n",
    "        years_df['Jounal'] = jou\n",
    "        years_df['paper_num'] = year_num\n",
    "        return years_df\n",
    "\n",
    "    # 统计每年的新作者\n",
    "    def year_new_author(self, years_df):\n",
    "        authors = list(years_df['seg_authors'])\n",
    "        new_author = [authors[0]]\n",
    "        for i in range(1, len(years_df)):\n",
    "            new = []\n",
    "            for j in authors[i]:\n",
    "                if j not in authors[i - 1]:\n",
    "                    new.append(j)\n",
    "            new_author.append(new)\n",
    "        return new_author\n",
    "\n",
    "    # 统计每年新作者提及数\n",
    "    def year_new_author_mention(self, pred_words, new_author, years):\n",
    "        newauthor_mens = []\n",
    "        group_df = self.data.groupby(by=['year'])\n",
    "        for word in pred_words:\n",
    "            for i in range(len(new_author)):\n",
    "                newauthor_men = self.mention(new_author, word, list(group_df.get_group(str(years[i]))['P_Summary']), \\\n",
    "                                             list(map(lambda x: x.split(),\n",
    "                                                      list(group_df.get_group(str(years[i]))['authors_seg']))))\n",
    "                newauthor_mens.append(newauthor_men)\n",
    "        return newauthor_mens\n",
    "\n",
    "    # 统计跨学科提及数\n",
    "    def multi_sub(self, pred_words, years):\n",
    "        multi_mens = []\n",
    "        group_df = self.data.groupby(by=['year'])\n",
    "        for word in pred_words:\n",
    "            for i in range(len(years)):\n",
    "                journals = self.multi_journal(word, list(group_df.get_group(str(years[i]))['P_Summary']), \\\n",
    "                                              list(group_df.get_group(str(years[i]))['P_Publication']))\n",
    "                multi_mens.append(journals)\n",
    "        return multi_mens\n",
    "\n",
    "    # 统计每个词初次在关键词中出现的年份\n",
    "    def first_year(self, pred_words, years_df):\n",
    "        f_year = []\n",
    "        pp = []\n",
    "        for w in range(len(pred_words)):\n",
    "            for y, i in zip(list(years_df['year']), list(years_df['seg_keywords'])):\n",
    "                if pred_words[w] in i:\n",
    "                    f_year.append(y)\n",
    "                    pp.append(w)\n",
    "                    break\n",
    "        return f_year\n",
    "\n",
    "    # 获取每个词18年的特征\n",
    "    def get_feature(self, years_df, pred_words, f_year, newauthor_mens, multi_mens):\n",
    "        year_num = len(years_df)\n",
    "        pp = pd.DataFrame()\n",
    "        for i in range(len(pred_words)):\n",
    "            word = pred_words[i]\n",
    "            fyear = f_year[i]\n",
    "            exist_year = []\n",
    "            for n, f in zip(list(years_df['year']), [fyear] * year_num):\n",
    "                e = n - f\n",
    "                if e < 0:\n",
    "                    exist_year.append(0)\n",
    "                else:\n",
    "                    exist_year.append(e)\n",
    "            dd = pd.DataFrame()\n",
    "            dd['word'] = [word] * year_num\n",
    "            dd['f1'] = self.feature(word, years_df)[0]\n",
    "            dd['f2'] = self.feature(word, years_df)[1]\n",
    "            dd['f3'] = exist_year\n",
    "            dd['f4'] = newauthor_mens[i * year_num:i * year_num + (year_num - 1)] + \\\n",
    "                       [self.pingjun(newauthor_mens[i * year_num + (year_num - 1) - 3:i * year_num + (year_num - 1)])]\n",
    "\n",
    "            dd['f6'] = multi_mens[i * year_num:i * year_num + (year_num - 1)] + \\\n",
    "                       [self.pingjun(multi_mens[i * year_num + (year_num - 1) - 3:i * year_num + (year_num - 1)])]\n",
    "\n",
    "            if i == 0:\n",
    "                pp = dd\n",
    "            else:\n",
    "                pp = pp.append(dd)\n",
    "        pp = pp.reset_index(drop=True)\n",
    "        return pp\n",
    "\n",
    "    # 预测某个词的词频\n",
    "    def zhidingword(self, search_word, test_data, model):\n",
    "        pre_data = test_data.loc[test_data.word == search_word].iloc[:, 1:]\n",
    "        result = model.predict(pre_data)\n",
    "        return int(result)\n",
    "\n",
    "    # 返回结果\n",
    "    def pre_result(self):\n",
    "        model_GBR = joblib.load(self.model_path)\n",
    "        pred_words = self.get_hotwords(self.hotword_num)\n",
    "        years = self.year_paper_num()[1]\n",
    "        group_df = self.year_paper_num()[0]\n",
    "        year_num = self.year_paper_num()[2]\n",
    "        years_df = self.groupby_year(group_df, years, year_num)\n",
    "        f_year = self.first_year(pred_words, years_df)\n",
    "        new_author = self.year_new_author(years_df)\n",
    "        newauthor_mens = self.year_new_author_mention(pred_words, new_author, years)\n",
    "        multi_mens = self.multi_sub(pred_words, years)\n",
    "        pp = self.get_feature(years_df, pred_words, f_year, newauthor_mens, multi_mens)\n",
    "\n",
    "        num = list(range(len(years) - 1, len(years) * self.hotword_num, len(years)))\n",
    "        test_data = pp.iloc[num]\n",
    "        all_wordtf = []\n",
    "        for word in pred_words:\n",
    "            result = self.zhidingword(word, test_data, model_GBR)\n",
    "            search_ke = list(pp.loc[pp.word == word]['f1']) + [result]\n",
    "            all_wordtf.extend(search_ke)\n",
    "        result = pd.DataFrame()\n",
    "        years.append(years[-1] + 1)\n",
    "        result['word'] = pred_words * len(years)\n",
    "        result['year'] = years * len(pred_words)\n",
    "        result['count'] = all_wordtf\n",
    "\n",
    "        word_2019 = result.loc[result['year'] == 2019]\n",
    "        word_2019_new = word_2019.sort_values(by=\"count\", ascending=False)\n",
    "        Top_hot_word = list(word_2019_new.loc[result['year'] == 2019]['word'])\n",
    "\n",
    "        hot_year = list(years)\n",
    "        freq_word = []\n",
    "        freq = []\n",
    "        freqs = []\n",
    "        for www in Top_hot_word:\n",
    "            freq_word.append(www)\n",
    "            freq = list(result.loc[result['word'] == www].sort_values(by=\"year\", ascending=True)['count'])\n",
    "            freqs.append(freq)\n",
    "        draw = pd.DataFrame()\n",
    "        draw[\"draw_word\"] = freq_word\n",
    "        draw[\"draw_freqs\"] = freqs\n",
    "        draw_dict = [{'draw_word': i[1], 'draw_freqs': i[2]} for i in draw.itertuples()]\n",
    "        #         draw_json=draw.to_json(orient='index')\n",
    "        altm = {'topnn': Top_hot_word, 'year': hot_year, 'draw': draw_dict}\n",
    "        return altm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T07:32:43.707911Z",
     "start_time": "2019-07-22T07:32:43.442808Z"
    }
   },
   "outputs": [],
   "source": [
    "esPaperObj = esPaperRetrieval(host='10.8.128.205',port=49200)\n",
    "docs = esPaperObj.Retrieval(titleQuery='',kwordQuery='',summaryQuery='医',pubQuery='',fromDate='2010-01-01',toDate='2019-01-01',volume=1000)\n",
    "\n",
    "hotPointObj = pre_word_count(json.dumps(docs), '../data/paper_data/paper_hotpoint.model',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T08:21:46.513642Z",
     "start_time": "2019-07-22T08:21:46.304170Z"
    }
   },
   "outputs": [],
   "source": [
    "hotPointObj1 = pre_word_count1(json.dumps(docs), '../data/paper_data/paper_hotpoint.model',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T08:21:54.661487Z",
     "start_time": "2019-07-22T08:21:47.460960Z"
    }
   },
   "outputs": [],
   "source": [
    "result=hotPointObj.pre_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T08:21:54.704585Z",
     "start_time": "2019-07-22T08:21:54.663761Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topnn': ['医患纠纷',\n",
       "  '北京市',\n",
       "  '文化',\n",
       "  '医学生',\n",
       "  '医患信任',\n",
       "  '医患双方',\n",
       "  '中医药法',\n",
       "  '问卷调查',\n",
       "  '中国医药学',\n",
       "  '医务人员',\n",
       "  '和谐',\n",
       "  '问题',\n",
       "  '医学人文教育',\n",
       "  '现状',\n",
       "  '培养模式',\n",
       "  '循证医学',\n",
       "  '县级中医医院',\n",
       "  '影响因素',\n",
       "  '医疗质量',\n",
       "  '医疗纠纷',\n",
       "  '中医药',\n",
       "  '人力资源',\n",
       "  '中医学',\n",
       "  '医联体',\n",
       "  '名医经验',\n",
       "  '医患关系',\n",
       "  '医德教育',\n",
       "  '综合医院',\n",
       "  '中西医结合',\n",
       "  '医院感染',\n",
       "  '全科医学',\n",
       "  '中医院',\n",
       "  '名老中医',\n",
       "  '上海',\n",
       "  '规范化培训',\n",
       "  '患者',\n",
       "  '中医学术史',\n",
       "  '医疗',\n",
       "  '中医',\n",
       "  '整合医学',\n",
       "  '医院建设项目',\n",
       "  '中西医结合医院',\n",
       "  '中医药大学',\n",
       "  '省级',\n",
       "  '分级诊疗',\n",
       "  '民族医',\n",
       "  '北京',\n",
       "  '公立医院',\n",
       "  '满意度',\n",
       "  '实践',\n",
       "  '临床医师',\n",
       "  '医疗机构',\n",
       "  '发展',\n",
       "  '医生',\n",
       "  '医师',\n",
       "  '中医医院',\n",
       "  '认知',\n",
       "  '医疗保险',\n",
       "  '对策',\n",
       "  '医家',\n",
       "  '医学伦理',\n",
       "  '军队医院',\n",
       "  '管理',\n",
       "  '临床科室',\n",
       "  '医学教育',\n",
       "  '文化建设',\n",
       "  '过度医疗',\n",
       "  '建议',\n",
       "  '医德医风',\n",
       "  '医疗改革',\n",
       "  '旴江医学',\n",
       "  '中医护理',\n",
       "  '医疗服务',\n",
       "  'WONCA',\n",
       "  '医疗费用',\n",
       "  '眼科医院',\n",
       "  '思考',\n",
       "  '中医药特色',\n",
       "  '医院文化',\n",
       "  '地方流派',\n",
       "  '国家中医药管理局',\n",
       "  '医院',\n",
       "  '新医改',\n",
       "  '医籍',\n",
       "  '医案',\n",
       "  '医德',\n",
       "  '调查',\n",
       "  '医学伦理学',\n",
       "  '中医医疗',\n",
       "  '建设',\n",
       "  '探讨',\n",
       "  '医学人文',\n",
       "  '医药',\n",
       "  '医院管理',\n",
       "  '创新',\n",
       "  '社区卫生服务',\n",
       "  '医患沟通',\n",
       "  '地域分布',\n",
       "  '住院医师',\n",
       "  '中医药文化'],\n",
       " 'year': [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019],\n",
       " 'draw': [{'draw_word': '医患纠纷', 'draw_freqs': [0, 9, 0, 0, 8, 0, 2, 8, 42]},\n",
       "  {'draw_word': '北京市', 'draw_freqs': [0, 9, 0, 4, 14, 0, 42, 3, 27]},\n",
       "  {'draw_word': '文化', 'draw_freqs': [2, 0, 45, 15, 3, 2, 0, 0, 26]},\n",
       "  {'draw_word': '医学生', 'draw_freqs': [0, 64, 15, 0, 11, 0, 8, 13, 25]},\n",
       "  {'draw_word': '医患信任', 'draw_freqs': [3, 0, 0, 165, 45, 2, 2, 4, 24]},\n",
       "  {'draw_word': '医患双方', 'draw_freqs': [11, 0, 0, 19, 10, 11, 15, 35, 23]},\n",
       "  {'draw_word': '中医药法', 'draw_freqs': [0, 86, 31, 9, 10, 2, 0, 0, 22]},\n",
       "  {'draw_word': '问卷调查', 'draw_freqs': [3, 0, 2, 0, 19, 2, 2, 47, 19]},\n",
       "  {'draw_word': '中国医药学', 'draw_freqs': [3, 0, 23, 22, 2, 3, 0, 0, 19]},\n",
       "  {'draw_word': '医务人员', 'draw_freqs': [16, 14, 4, 7, 2, 22, 2, 0, 19]},\n",
       "  {'draw_word': '和谐', 'draw_freqs': [0, 8, 2, 0, 0, 33, 2, 0, 16]},\n",
       "  {'draw_word': '问题', 'draw_freqs': [2, 0, 12, 15, 6, 0, 6, 4, 15]},\n",
       "  {'draw_word': '医学人文教育', 'draw_freqs': [7, 0, 1, 0, 5, 0, 0, 0, 14]},\n",
       "  {'draw_word': '现状', 'draw_freqs': [0, 5, 12, 17, 0, 9, 4, 4, 14]},\n",
       "  {'draw_word': '培养模式', 'draw_freqs': [2, 0, 16, 0, 0, 98, 45, 0, 13]},\n",
       "  {'draw_word': '循证医学', 'draw_freqs': [0, 0, 8, 2, 0, 2, 16, 0, 13]},\n",
       "  {'draw_word': '县级中医医院', 'draw_freqs': [20, 6, 35, 22, 0, 0, 6, 4, 13]},\n",
       "  {'draw_word': '影响因素', 'draw_freqs': [2, 8, 0, 4, 89, 9, 15, 0, 12]},\n",
       "  {'draw_word': '医疗质量', 'draw_freqs': [2, 2, 8, 0, 4, 17, 16, 41, 12]},\n",
       "  {'draw_word': '医疗纠纷', 'draw_freqs': [4, 1, 0, 37, 0, 14, 0, 0, 12]},\n",
       "  {'draw_word': '中医药', 'draw_freqs': [2, 0, 3, 20, 4, 8, 8, 2, 12]},\n",
       "  {'draw_word': '人力资源', 'draw_freqs': [17, 4, 11, 0, 0, 2, 0, 0, 12]},\n",
       "  {'draw_word': '中医学', 'draw_freqs': [9, 0, 1, 52, 5, 14, 20, 8, 11]},\n",
       "  {'draw_word': '医联体', 'draw_freqs': [14, 0, 0, 0, 12, 10, 17, 2, 11]},\n",
       "  {'draw_word': '名医经验', 'draw_freqs': [0, 11, 0, 6, 6, 0, 0, 9, 11]},\n",
       "  {'draw_word': '医患关系', 'draw_freqs': [16, 0, 2, 6, 0, 0, 4, 0, 11]},\n",
       "  {'draw_word': '医德教育', 'draw_freqs': [40, 5, 2, 5, 11, 10, 8, 8, 10]},\n",
       "  {'draw_word': '综合医院', 'draw_freqs': [0, 8, 3, 21, 10, 0, 15, 0, 10]},\n",
       "  {'draw_word': '中西医结合', 'draw_freqs': [0, 0, 0, 0, 59, 42, 2, 2, 9]},\n",
       "  {'draw_word': '医院感染', 'draw_freqs': [3, 7, 4, 2, 6, 0, 5, 7, 8]},\n",
       "  {'draw_word': '全科医学', 'draw_freqs': [1, 0, 0, 0, 3, 1, 16, 0, 8]},\n",
       "  {'draw_word': '中医院', 'draw_freqs': [13, 0, 9, 0, 1, 7, 0, 36, 8]},\n",
       "  {'draw_word': '名老中医', 'draw_freqs': [2, 8, 0, 14, 5, 12, 4, 0, 8]},\n",
       "  {'draw_word': '上海', 'draw_freqs': [2, 24, 5, 23, 8, 22, 0, 0, 8]},\n",
       "  {'draw_word': '规范化培训', 'draw_freqs': [3, 0, 0, 4, 0, 29, 0, 7, 8]},\n",
       "  {'draw_word': '患者', 'draw_freqs': [2, 2, 0, 2, 14, 0, 19, 6, 7]},\n",
       "  {'draw_word': '中医学术史', 'draw_freqs': [0, 0, 0, 0, 8, 4, 26, 6, 6]},\n",
       "  {'draw_word': '医疗', 'draw_freqs': [2, 6, 0, 2, 0, 24, 6, 2, 6]},\n",
       "  {'draw_word': '中医', 'draw_freqs': [0, 0, 3, 0, 12, 8, 4, 5, 6]},\n",
       "  {'draw_word': '整合医学', 'draw_freqs': [0, 38, 17, 2, 0, 0, 0, 79, 6]},\n",
       "  {'draw_word': '医院建设项目', 'draw_freqs': [0, 0, 0, 7, 17, 6, 0, 4, 5]},\n",
       "  {'draw_word': '中西医结合医院', 'draw_freqs': [3, 2, 0, 23, 3, 0, 143, 0, 5]},\n",
       "  {'draw_word': '中医药大学', 'draw_freqs': [4, 2, 31, 4, 10, 0, 12, 10, 5]},\n",
       "  {'draw_word': '省级', 'draw_freqs': [12, 4, 3, 39, 36, 5, 13, 0, 4]},\n",
       "  {'draw_word': '分级诊疗', 'draw_freqs': [12, 4, 4, 5, 0, 8, 0, 2, 4]},\n",
       "  {'draw_word': '民族医', 'draw_freqs': [1, 0, 16, 1, 2, 97, 18, 4, 4]},\n",
       "  {'draw_word': '北京', 'draw_freqs': [16, 6, 18, 17, 0, 26, 0, 2, 4]},\n",
       "  {'draw_word': '公立医院', 'draw_freqs': [5, 2, 2, 56, 6, 0, 2, 2, 4]},\n",
       "  {'draw_word': '满意度', 'draw_freqs': [29, 12, 0, 16, 3, 2, 0, 6, 4]},\n",
       "  {'draw_word': '实践', 'draw_freqs': [22, 2, 2, 25, 0, 15, 0, 2, 4]},\n",
       "  {'draw_word': '临床医师', 'draw_freqs': [0, 0, 94, 34, 3, 4, 7, 14, 4]},\n",
       "  {'draw_word': '医疗机构', 'draw_freqs': [60, 13, 2, 0, 2, 0, 6, 22, 4]},\n",
       "  {'draw_word': '发展', 'draw_freqs': [32, 8, 23, 11, 2, 5, 8, 0, 4]},\n",
       "  {'draw_word': '医生', 'draw_freqs': [2, 0, 0, 0, 13, 16, 16, 3, 4]},\n",
       "  {'draw_word': '医师', 'draw_freqs': [59, 8, 5, 1, 7, 12, 27, 0, 4]},\n",
       "  {'draw_word': '中医医院', 'draw_freqs': [3, 33, 0, 3, 0, 6, 6, 4, 3]},\n",
       "  {'draw_word': '认知', 'draw_freqs': [12, 0, 3, 17, 52, 13, 2, 0, 3]},\n",
       "  {'draw_word': '医疗保险', 'draw_freqs': [2, 49, 6, 10, 15, 25, 0, 0, 3]},\n",
       "  {'draw_word': '对策', 'draw_freqs': [47, 7, 4, 4, 6, 5, 6, 0, 3]},\n",
       "  {'draw_word': '医家', 'draw_freqs': [2, 5, 12, 17, 28, 36, 2, 4, 3]},\n",
       "  {'draw_word': '医学伦理', 'draw_freqs': [2, 0, 54, 11, 7, 1, 5, 0, 3]},\n",
       "  {'draw_word': '军队医院', 'draw_freqs': [2, 10, 0, 0, 83, 44, 6, 0, 3]},\n",
       "  {'draw_word': '管理', 'draw_freqs': [0, 0, 11, 8, 5, 62, 0, 2, 3]},\n",
       "  {'draw_word': '临床科室', 'draw_freqs': [1, 0, 36, 14, 3, 25, 20, 0, 3]},\n",
       "  {'draw_word': '医学教育', 'draw_freqs': [8, 39, 6, 4, 0, 0, 109, 20, 3]},\n",
       "  {'draw_word': '文化建设', 'draw_freqs': [0, 0, 2, 18, 21, 11, 12, 9, 3]},\n",
       "  {'draw_word': '过度医疗', 'draw_freqs': [7, 21, 15, 22, 0, 0, 15, 0, 3]},\n",
       "  {'draw_word': '建议', 'draw_freqs': [14, 0, 10, 2, 0, 13, 0, 1, 3]},\n",
       "  {'draw_word': '医德医风', 'draw_freqs': [0, 11, 0, 0, 30, 2, 12, 4, 3]},\n",
       "  {'draw_word': '医疗改革', 'draw_freqs': [0, 0, 19, 0, 5, 11, 12, 0, 2]},\n",
       "  {'draw_word': '旴江医学', 'draw_freqs': [1, 0, 21, 2, 25, 3, 11, 0, 2]},\n",
       "  {'draw_word': '中医护理', 'draw_freqs': [5, 42, 16, 2, 10, 0, 10, 0, 2]},\n",
       "  {'draw_word': '医疗服务', 'draw_freqs': [0, 47, 8, 2, 6, 11, 0, 8, 2]},\n",
       "  {'draw_word': 'WONCA', 'draw_freqs': [0, 0, 2, 0, 55, 0, 28, 0, 2]},\n",
       "  {'draw_word': '医疗费用', 'draw_freqs': [0, 4, 0, 2, 4, 4, 3, 0, 2]},\n",
       "  {'draw_word': '眼科医院', 'draw_freqs': [35, 0, 23, 1, 11, 2, 0, 2, 2]},\n",
       "  {'draw_word': '思考', 'draw_freqs': [3, 0, 0, 20, 1, 7, 9, 16, 2]},\n",
       "  {'draw_word': '中医药特色', 'draw_freqs': [0, 4, 1, 1, 0, 8, 0, 23, 1]},\n",
       "  {'draw_word': '医院文化', 'draw_freqs': [2, 0, 5, 0, 0, 0, 17, 3, 0]},\n",
       "  {'draw_word': '地方流派', 'draw_freqs': [0, 15, 0, 6, 8, 11, 2, 7, 0]},\n",
       "  {'draw_word': '国家中医药管理局', 'draw_freqs': [9, 4, 2, 2, 0, 47, 8, 0, 0]},\n",
       "  {'draw_word': '医院', 'draw_freqs': [6, 14, 26, 8, 9, 2, 43, 0, 0]},\n",
       "  {'draw_word': '新医改', 'draw_freqs': [29, 8, 0, 4, 1, 0, 25, 0, 0]},\n",
       "  {'draw_word': '医籍', 'draw_freqs': [2, 3, 9, 0, 31, 13, 23, 0, 0]},\n",
       "  {'draw_word': '医案', 'draw_freqs': [34, 0, 0, 10, 3, 0, 6, 6, -1]},\n",
       "  {'draw_word': '医德', 'draw_freqs': [13, 0, 6, 8, 26, 14, 0, 54, -1]},\n",
       "  {'draw_word': '调查', 'draw_freqs': [0, 0, 39, 12, 10, 6, 28, 4, -1]},\n",
       "  {'draw_word': '医学伦理学', 'draw_freqs': [5, 0, 0, 7, 0, 30, 6, 10, -1]},\n",
       "  {'draw_word': '中医医疗', 'draw_freqs': [0, 8, 0, 12, 15, 2, 84, 53, -2]},\n",
       "  {'draw_word': '建设', 'draw_freqs': [6, 0, 2, 8, 0, 0, 34, 3, -2]},\n",
       "  {'draw_word': '探讨', 'draw_freqs': [25, 14, 2, 4, 0, 170, 49, 0, -2]},\n",
       "  {'draw_word': '医学人文', 'draw_freqs': [7, 0, 32, 2, 9, 21, 0, 1, -2]},\n",
       "  {'draw_word': '医药', 'draw_freqs': [0, 2, 14, 2, 0, 0, 0, 9, -2]},\n",
       "  {'draw_word': '医院管理', 'draw_freqs': [0, 4, 0, 1, 2, 4, 112, 5, -3]},\n",
       "  {'draw_word': '创新', 'draw_freqs': [0, 10, 2, 0, 93, 48, 2, 14, -3]},\n",
       "  {'draw_word': '社区卫生服务', 'draw_freqs': [0, 12, 31, 7, 4, 10, 2, 2, -3]},\n",
       "  {'draw_word': '医患沟通', 'draw_freqs': [0, 3, 0, 5, 12, 8, 14, 18, -3]},\n",
       "  {'draw_word': '地域分布', 'draw_freqs': [0, 0, 1, 13, 2, 39, 13, 21, -3]},\n",
       "  {'draw_word': '住院医师', 'draw_freqs': [0, 0, 4, 9, 34, 8, 0, 9, -3]},\n",
       "  {'draw_word': '中医药文化', 'draw_freqs': [0, 12, 12, 29, 27, 3, 6, 9, -3]}]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T07:52:26.092006Z",
     "start_time": "2019-07-22T07:52:18.119125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topnn': ['医患纠纷',\n",
       "  '北京市',\n",
       "  '文化',\n",
       "  '医学生',\n",
       "  '医患信任',\n",
       "  '医患双方',\n",
       "  '中医药法',\n",
       "  '问卷调查',\n",
       "  '中国医药学',\n",
       "  '医务人员',\n",
       "  '和谐',\n",
       "  '问题',\n",
       "  '医学人文教育',\n",
       "  '现状',\n",
       "  '培养模式',\n",
       "  '循证医学',\n",
       "  '县级中医医院',\n",
       "  '影响因素',\n",
       "  '医疗质量',\n",
       "  '医疗纠纷',\n",
       "  '中医药',\n",
       "  '人力资源',\n",
       "  '中医学',\n",
       "  '医联体',\n",
       "  '名医经验',\n",
       "  '医患关系',\n",
       "  '医德教育',\n",
       "  '综合医院',\n",
       "  '中西医结合',\n",
       "  '医院感染',\n",
       "  '全科医学',\n",
       "  '中医院',\n",
       "  '名老中医',\n",
       "  '上海',\n",
       "  '规范化培训',\n",
       "  '患者',\n",
       "  '中医学术史',\n",
       "  '医疗',\n",
       "  '中医',\n",
       "  '整合医学',\n",
       "  '医院建设项目',\n",
       "  '中西医结合医院',\n",
       "  '中医药大学',\n",
       "  '省级',\n",
       "  '分级诊疗',\n",
       "  '民族医',\n",
       "  '北京',\n",
       "  '公立医院',\n",
       "  '满意度',\n",
       "  '实践',\n",
       "  '临床医师',\n",
       "  '医疗机构',\n",
       "  '发展',\n",
       "  '医生',\n",
       "  '医师',\n",
       "  '中医医院',\n",
       "  '认知',\n",
       "  '医疗保险',\n",
       "  '对策',\n",
       "  '医家',\n",
       "  '医学伦理',\n",
       "  '军队医院',\n",
       "  '管理',\n",
       "  '临床科室',\n",
       "  '医学教育',\n",
       "  '文化建设',\n",
       "  '过度医疗',\n",
       "  '建议',\n",
       "  '医德医风',\n",
       "  '医疗改革',\n",
       "  '旴江医学',\n",
       "  '中医护理',\n",
       "  '医疗服务',\n",
       "  'WONCA',\n",
       "  '医疗费用',\n",
       "  '眼科医院',\n",
       "  '思考',\n",
       "  '中医药特色',\n",
       "  '医院文化',\n",
       "  '地方流派',\n",
       "  '国家中医药管理局',\n",
       "  '医院',\n",
       "  '新医改',\n",
       "  '医籍',\n",
       "  '医案',\n",
       "  '医德',\n",
       "  '调查',\n",
       "  '医学伦理学',\n",
       "  '中医医疗',\n",
       "  '建设',\n",
       "  '探讨',\n",
       "  '医学人文',\n",
       "  '医药',\n",
       "  '医院管理',\n",
       "  '创新',\n",
       "  '社区卫生服务',\n",
       "  '医患沟通',\n",
       "  '地域分布',\n",
       "  '住院医师',\n",
       "  '中医药文化'],\n",
       " 'year': [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019],\n",
       " 'draw': [{'draw_word': '医患纠纷', 'draw_freqs': [0, 9, 0, 0, 8, 0, 2, 8, 42]},\n",
       "  {'draw_word': '北京市', 'draw_freqs': [0, 9, 0, 4, 14, 0, 42, 3, 27]},\n",
       "  {'draw_word': '文化', 'draw_freqs': [2, 0, 45, 15, 3, 2, 0, 0, 26]},\n",
       "  {'draw_word': '医学生', 'draw_freqs': [0, 64, 15, 0, 11, 0, 8, 13, 25]},\n",
       "  {'draw_word': '医患信任', 'draw_freqs': [3, 0, 0, 165, 45, 2, 2, 4, 24]},\n",
       "  {'draw_word': '医患双方', 'draw_freqs': [11, 0, 0, 19, 10, 11, 15, 35, 23]},\n",
       "  {'draw_word': '中医药法', 'draw_freqs': [0, 86, 31, 9, 10, 2, 0, 0, 22]},\n",
       "  {'draw_word': '问卷调查', 'draw_freqs': [3, 0, 2, 0, 19, 2, 2, 47, 19]},\n",
       "  {'draw_word': '中国医药学', 'draw_freqs': [3, 0, 23, 22, 2, 3, 0, 0, 19]},\n",
       "  {'draw_word': '医务人员', 'draw_freqs': [16, 14, 4, 7, 2, 22, 2, 0, 19]},\n",
       "  {'draw_word': '和谐', 'draw_freqs': [0, 8, 2, 0, 0, 33, 2, 0, 16]},\n",
       "  {'draw_word': '问题', 'draw_freqs': [2, 0, 12, 15, 6, 0, 6, 4, 15]},\n",
       "  {'draw_word': '医学人文教育', 'draw_freqs': [7, 0, 1, 0, 5, 0, 0, 0, 14]},\n",
       "  {'draw_word': '现状', 'draw_freqs': [0, 5, 12, 17, 0, 9, 4, 4, 14]},\n",
       "  {'draw_word': '培养模式', 'draw_freqs': [2, 0, 16, 0, 0, 98, 45, 0, 13]},\n",
       "  {'draw_word': '循证医学', 'draw_freqs': [0, 0, 8, 2, 0, 2, 16, 0, 13]},\n",
       "  {'draw_word': '县级中医医院', 'draw_freqs': [20, 6, 35, 22, 0, 0, 6, 4, 13]},\n",
       "  {'draw_word': '影响因素', 'draw_freqs': [2, 8, 0, 4, 89, 9, 15, 0, 12]},\n",
       "  {'draw_word': '医疗质量', 'draw_freqs': [2, 2, 8, 0, 4, 17, 16, 41, 12]},\n",
       "  {'draw_word': '医疗纠纷', 'draw_freqs': [4, 1, 0, 37, 0, 14, 0, 0, 12]},\n",
       "  {'draw_word': '中医药', 'draw_freqs': [2, 0, 3, 20, 4, 8, 8, 2, 12]},\n",
       "  {'draw_word': '人力资源', 'draw_freqs': [17, 4, 11, 0, 0, 2, 0, 0, 12]},\n",
       "  {'draw_word': '中医学', 'draw_freqs': [9, 0, 1, 52, 5, 14, 20, 8, 11]},\n",
       "  {'draw_word': '医联体', 'draw_freqs': [14, 0, 0, 0, 12, 10, 17, 2, 11]},\n",
       "  {'draw_word': '名医经验', 'draw_freqs': [0, 11, 0, 6, 6, 0, 0, 9, 11]},\n",
       "  {'draw_word': '医患关系', 'draw_freqs': [16, 0, 2, 6, 0, 0, 4, 0, 11]},\n",
       "  {'draw_word': '医德教育', 'draw_freqs': [40, 5, 2, 5, 11, 10, 8, 8, 10]},\n",
       "  {'draw_word': '综合医院', 'draw_freqs': [0, 8, 3, 21, 10, 0, 15, 0, 10]},\n",
       "  {'draw_word': '中西医结合', 'draw_freqs': [0, 0, 0, 0, 59, 42, 2, 2, 9]},\n",
       "  {'draw_word': '医院感染', 'draw_freqs': [3, 7, 4, 2, 6, 0, 5, 7, 8]},\n",
       "  {'draw_word': '全科医学', 'draw_freqs': [1, 0, 0, 0, 3, 1, 16, 0, 8]},\n",
       "  {'draw_word': '中医院', 'draw_freqs': [13, 0, 9, 0, 1, 7, 0, 36, 8]},\n",
       "  {'draw_word': '名老中医', 'draw_freqs': [2, 8, 0, 14, 5, 12, 4, 0, 8]},\n",
       "  {'draw_word': '上海', 'draw_freqs': [2, 24, 5, 23, 8, 22, 0, 0, 8]},\n",
       "  {'draw_word': '规范化培训', 'draw_freqs': [3, 0, 0, 4, 0, 29, 0, 7, 8]},\n",
       "  {'draw_word': '患者', 'draw_freqs': [2, 2, 0, 2, 14, 0, 19, 6, 7]},\n",
       "  {'draw_word': '中医学术史', 'draw_freqs': [0, 0, 0, 0, 8, 4, 26, 6, 6]},\n",
       "  {'draw_word': '医疗', 'draw_freqs': [2, 6, 0, 2, 0, 24, 6, 2, 6]},\n",
       "  {'draw_word': '中医', 'draw_freqs': [0, 0, 3, 0, 12, 8, 4, 5, 6]},\n",
       "  {'draw_word': '整合医学', 'draw_freqs': [0, 38, 17, 2, 0, 0, 0, 79, 6]},\n",
       "  {'draw_word': '医院建设项目', 'draw_freqs': [0, 0, 0, 7, 17, 6, 0, 4, 5]},\n",
       "  {'draw_word': '中西医结合医院', 'draw_freqs': [3, 2, 0, 23, 3, 0, 143, 0, 5]},\n",
       "  {'draw_word': '中医药大学', 'draw_freqs': [4, 2, 31, 4, 10, 0, 12, 10, 5]},\n",
       "  {'draw_word': '省级', 'draw_freqs': [12, 4, 3, 39, 36, 5, 13, 0, 4]},\n",
       "  {'draw_word': '分级诊疗', 'draw_freqs': [12, 4, 4, 5, 0, 8, 0, 2, 4]},\n",
       "  {'draw_word': '民族医', 'draw_freqs': [1, 0, 16, 1, 2, 97, 18, 4, 4]},\n",
       "  {'draw_word': '北京', 'draw_freqs': [16, 6, 18, 17, 0, 26, 0, 2, 4]},\n",
       "  {'draw_word': '公立医院', 'draw_freqs': [5, 2, 2, 56, 6, 0, 2, 2, 4]},\n",
       "  {'draw_word': '满意度', 'draw_freqs': [29, 12, 0, 16, 3, 2, 0, 6, 4]},\n",
       "  {'draw_word': '实践', 'draw_freqs': [22, 2, 2, 25, 0, 15, 0, 2, 4]},\n",
       "  {'draw_word': '临床医师', 'draw_freqs': [0, 0, 94, 34, 3, 4, 7, 14, 4]},\n",
       "  {'draw_word': '医疗机构', 'draw_freqs': [60, 13, 2, 0, 2, 0, 6, 22, 4]},\n",
       "  {'draw_word': '发展', 'draw_freqs': [32, 8, 23, 11, 2, 5, 8, 0, 4]},\n",
       "  {'draw_word': '医生', 'draw_freqs': [2, 0, 0, 0, 13, 16, 16, 3, 4]},\n",
       "  {'draw_word': '医师', 'draw_freqs': [59, 8, 5, 1, 7, 12, 27, 0, 4]},\n",
       "  {'draw_word': '中医医院', 'draw_freqs': [3, 33, 0, 3, 0, 6, 6, 4, 3]},\n",
       "  {'draw_word': '认知', 'draw_freqs': [12, 0, 3, 17, 52, 13, 2, 0, 3]},\n",
       "  {'draw_word': '医疗保险', 'draw_freqs': [2, 49, 6, 10, 15, 25, 0, 0, 3]},\n",
       "  {'draw_word': '对策', 'draw_freqs': [47, 7, 4, 4, 6, 5, 6, 0, 3]},\n",
       "  {'draw_word': '医家', 'draw_freqs': [2, 5, 12, 17, 28, 36, 2, 4, 3]},\n",
       "  {'draw_word': '医学伦理', 'draw_freqs': [2, 0, 54, 11, 7, 1, 5, 0, 3]},\n",
       "  {'draw_word': '军队医院', 'draw_freqs': [2, 10, 0, 0, 83, 44, 6, 0, 3]},\n",
       "  {'draw_word': '管理', 'draw_freqs': [0, 0, 11, 8, 5, 62, 0, 2, 3]},\n",
       "  {'draw_word': '临床科室', 'draw_freqs': [1, 0, 36, 14, 3, 25, 20, 0, 3]},\n",
       "  {'draw_word': '医学教育', 'draw_freqs': [8, 39, 6, 4, 0, 0, 109, 20, 3]},\n",
       "  {'draw_word': '文化建设', 'draw_freqs': [0, 0, 2, 18, 21, 11, 12, 9, 3]},\n",
       "  {'draw_word': '过度医疗', 'draw_freqs': [7, 21, 15, 22, 0, 0, 15, 0, 3]},\n",
       "  {'draw_word': '建议', 'draw_freqs': [14, 0, 10, 2, 0, 13, 0, 1, 3]},\n",
       "  {'draw_word': '医德医风', 'draw_freqs': [0, 11, 0, 0, 30, 2, 12, 4, 3]},\n",
       "  {'draw_word': '医疗改革', 'draw_freqs': [0, 0, 19, 0, 5, 11, 12, 0, 2]},\n",
       "  {'draw_word': '旴江医学', 'draw_freqs': [1, 0, 21, 2, 25, 3, 11, 0, 2]},\n",
       "  {'draw_word': '中医护理', 'draw_freqs': [5, 42, 16, 2, 10, 0, 10, 0, 2]},\n",
       "  {'draw_word': '医疗服务', 'draw_freqs': [0, 47, 8, 2, 6, 11, 0, 8, 2]},\n",
       "  {'draw_word': 'WONCA', 'draw_freqs': [0, 0, 2, 0, 55, 0, 28, 0, 2]},\n",
       "  {'draw_word': '医疗费用', 'draw_freqs': [0, 4, 0, 2, 4, 4, 3, 0, 2]},\n",
       "  {'draw_word': '眼科医院', 'draw_freqs': [35, 0, 23, 1, 11, 2, 0, 2, 2]},\n",
       "  {'draw_word': '思考', 'draw_freqs': [3, 0, 0, 20, 1, 7, 9, 16, 2]},\n",
       "  {'draw_word': '中医药特色', 'draw_freqs': [0, 4, 1, 1, 0, 8, 0, 23, 1]},\n",
       "  {'draw_word': '医院文化', 'draw_freqs': [2, 0, 5, 0, 0, 0, 17, 3, 0]},\n",
       "  {'draw_word': '地方流派', 'draw_freqs': [0, 15, 0, 6, 8, 11, 2, 7, 0]},\n",
       "  {'draw_word': '国家中医药管理局', 'draw_freqs': [9, 4, 2, 2, 0, 47, 8, 0, 0]},\n",
       "  {'draw_word': '医院', 'draw_freqs': [6, 14, 26, 8, 9, 2, 43, 0, 0]},\n",
       "  {'draw_word': '新医改', 'draw_freqs': [29, 8, 0, 4, 1, 0, 25, 0, 0]},\n",
       "  {'draw_word': '医籍', 'draw_freqs': [2, 3, 9, 0, 31, 13, 23, 0, 0]},\n",
       "  {'draw_word': '医案', 'draw_freqs': [34, 0, 0, 10, 3, 0, 6, 6, -1]},\n",
       "  {'draw_word': '医德', 'draw_freqs': [13, 0, 6, 8, 26, 14, 0, 54, -1]},\n",
       "  {'draw_word': '调查', 'draw_freqs': [0, 0, 39, 12, 10, 6, 28, 4, -1]},\n",
       "  {'draw_word': '医学伦理学', 'draw_freqs': [5, 0, 0, 7, 0, 30, 6, 10, -1]},\n",
       "  {'draw_word': '中医医疗', 'draw_freqs': [0, 8, 0, 12, 15, 2, 84, 53, -2]},\n",
       "  {'draw_word': '建设', 'draw_freqs': [6, 0, 2, 8, 0, 0, 34, 3, -2]},\n",
       "  {'draw_word': '探讨', 'draw_freqs': [25, 14, 2, 4, 0, 170, 49, 0, -2]},\n",
       "  {'draw_word': '医学人文', 'draw_freqs': [7, 0, 32, 2, 9, 21, 0, 1, -2]},\n",
       "  {'draw_word': '医药', 'draw_freqs': [0, 2, 14, 2, 0, 0, 0, 9, -2]},\n",
       "  {'draw_word': '医院管理', 'draw_freqs': [0, 4, 0, 1, 2, 4, 112, 5, -3]},\n",
       "  {'draw_word': '创新', 'draw_freqs': [0, 10, 2, 0, 93, 48, 2, 14, -3]},\n",
       "  {'draw_word': '社区卫生服务', 'draw_freqs': [0, 12, 31, 7, 4, 10, 2, 2, -3]},\n",
       "  {'draw_word': '医患沟通', 'draw_freqs': [0, 3, 0, 5, 12, 8, 14, 18, -3]},\n",
       "  {'draw_word': '地域分布', 'draw_freqs': [0, 0, 1, 13, 2, 39, 13, 21, -3]},\n",
       "  {'draw_word': '住院医师', 'draw_freqs': [0, 0, 4, 9, 34, 8, 0, 9, -3]},\n",
       "  {'draw_word': '中医药文化', 'draw_freqs': [0, 12, 12, 29, 27, 3, 6, 9, -3]}]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotPointObj1.pre_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
